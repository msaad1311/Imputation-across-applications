{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imputation across applications.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6KjAPfe63t/G2UTVHOJTe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msaad1311/Imputation-across-applications/blob/master/Imputation_across_applications.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6dqH_Mkydcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "9cd88f21-6235-43e5-ee2d-91355303ab29"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# import reader\n",
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "import sklearn.model_selection\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "# import autosklearn.regression\n",
        "from sklearn import ensemble\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIzU7ohYyjhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None, label=None):\n",
        "    plt.plot(time[start:end], series[start:end], format, label=label)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    if label:\n",
        "        plt.legend(fontsize=14)\n",
        "    plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwSZdWHAymvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trend(time, slope=0):\n",
        "    return slope * time+50\n",
        "def white_noise(time, noise_level=1, seed=None):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    return rnd.randn(len(time)) * noise_level"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhwoZz1ryp9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time = np.arange(4 * 365 + 1)+50\n",
        "baseline = 10\n",
        "series = trend(time, 0.1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, series)\n",
        "plt.show()\n",
        "series.min()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9CmdXxhjFe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.arange(10)+10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ECK5S6HyyRa",
        "colab_type": "text"
      },
      "source": [
        "Adding noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXH3IgQHy226",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "series.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9rM5KW7zJQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "noise = np.random.normal(0,10,1461)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J6Yy9x3zZrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSu2AEfvzbFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "series_noise = series+noise\n",
        "# series_noise=series_noise.clip(0,series_noise.max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqyQpBtyzec2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_series(time, series_noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSZPylAQgy_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "series_noise.min()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM1E6pKJziVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "series_missing=np.copy(series_noise)\n",
        "for i in range(1,len(series_noise)):\n",
        "    if random.random()<= 0.5:\n",
        "        series_missing[i]=np.nan\n",
        "    \n",
        "'''\n",
        "def misser (df,missing_percent = 0.5):\n",
        "  for i in df.columns:\n",
        "    for j, row_value in df[i].iteritems():\n",
        "      if j==0:\n",
        "        continue\n",
        "      else:\n",
        "        if random.random() <= missing_percent:\n",
        "            df[i][j] = np.nan\n",
        "  return df\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEGtEHAF3lb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.count_nonzero(np.isnan(series_noise)),np.count_nonzero(np.isnan(series_missing))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmykK8p34jrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot_series(time,series_noise)\n",
        "plot_series(time,series_missing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJsFp49E24jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_original= pd.DataFrame(series_noise,columns=['Series'])\n",
        "df_missing= pd.DataFrame(series_missing,columns=['Series'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIsMSpWTVknI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_missing.fillna(-1.0).to_excel('Trend Missing.xlsx')\n",
        "df_original.to_excel('Trend Original.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4pkAvMO3tPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_missing.fillna(-1.0).to_csv('miss_data1.txt', header=None, index=None, sep='\\t', mode='a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k4fxbSo4TDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LIMELSTM.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SrkSCXU42Dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_lstm = pd.read_excel('/content/imputed_data_ for LSTM_trend.xlsx')\n",
        "mse(df_original,df_lstm),mse(df_original,df_missing.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXIQIn1i7rVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(df_lstm[0],color='r')\n",
        "# plt.plot(df_missing,color='b')\n",
        "plt.plot(df_original,color='b')\n",
        "# plt.plot(df_missing.interpolate(),color='g')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUGnmV_RJ1_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LIMEGRU.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foVkzAXBKMbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_gru = pd.read_excel('/content/imputed_data_ for GRU_trend.xlsx')\n",
        "mse(df_original,df_gru),mse(df_original,df_missing.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bcPkFx2Koaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Hybrid.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3_WfYQXLQ9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_hyd = pd.read_excel('/content/imputed_data_ for Hybrid_trend.xlsx')\n",
        "mse(df_original,df_hyd),mse(df_original,df_missing.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK2Ejl7dPQcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Residual.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrtLNfa3Q1ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_res = pd.read_excel('/content/imputed_data_ for Residue_trend.xlsx')\n",
        "mse(df_original,df_res),mse(df_original,df_missing.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVNRMB0SRsim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Random.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN6nKRS23o6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_ran3 = pd.read_excel('/content/imputed_data_ for Random1_trend.xlsx')\n",
        "mse(df_original,df_ran3),mse(df_original,df_missing.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13mbLK-0lSeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Hybrid_multiple.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gYMgcOY5pjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_hyd_trend = pd.read_excel('/content/imputed_data_ for Hybrid multiple Trend.xlsx')\n",
        "mse(df_original,df_hyd_trend),mse(df_original,df_missing.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB7BgwJ96lKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python GRU_Deep.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhKX_Q7z7rGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_grud = pd.read_excel('/content/imputed_data_ for GRU_deep_trend.xlsx')\n",
        "mse(df_original,df_grud),mse(df_original,df_missing.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpjb3vl2YgeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_missing.interpolate(limit_direction='both').to_excel('Trend Linear.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0VF4bpyYNbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ecal = pd.read_excel('/content/MSE for python.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Puz-SE5sYZ3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ecal.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td9yr0dyY-g4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ecal = pd.read_excel('/content/MSE for python.xlsx')\n",
        "ecal.head()\n",
        "for i in ecal.columns:\n",
        "    print('the mse for',i,'is:',mse(ecal['Original'],ecal[i]))\n",
        "\n",
        "for i in ecal.columns:\n",
        "    print('the mse for',i,'is:',mse(ecal['Original'],ecal[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU1T9guH2utw",
        "colab_type": "text"
      },
      "source": [
        "Seasonality\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QO6-vYt2wXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seasonal_pattern(season_time):\n",
        "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n",
        "    return np.where(season_time < 0.4,\n",
        "                    np.cos(season_time * 2 * np.pi),\n",
        "                    1 / np.exp(3 * season_time))\n",
        "\n",
        "def seasonality(time, period, amplitude=1, phase=0):\n",
        "    \"\"\"Repeats the same pattern at each period\"\"\"\n",
        "    season_time = ((time + phase) % period) / period\n",
        "    return amplitude * seasonal_pattern(season_time) + 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rv1ZDx62x-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseline = 10\n",
        "amplitude = 40\n",
        "series_seasonal = seasonality(time, period=365, amplitude=amplitude)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, series_seasonal)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyzNExjV3OUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "series_seasonal.min(),series_seasonal.max(),series_seasonal.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re0hV2nL3rSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "noise = np.random.normal(0,10,1461)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wMJVll73xbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seasonal_noise = series_seasonal+noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "025b44DU319f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, seasonal_noise)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT6mkzUL4V7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seasonal_noise.min(),seasonal_noise.max(),seasonal_noise.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Zp-IMw3lFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "series_missing_seasonal=np.copy(seasonal_noise)\n",
        "for i in range(1,len(seasonal_noise)):\n",
        "    if random.random()<= 0.5:\n",
        "        series_missing_seasonal[i]=np.nan\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-XGX_MB4jP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.count_nonzero(np.isnan(seasonal_noise)),np.count_nonzero(np.isnan(series_missing_seasonal))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x3cmB_-4wVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_series(time,series_missing_seasonal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImTNZQNV41P4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_original_season= pd.DataFrame(seasonal_noise,columns=['Series'])\n",
        "df_missing_season= pd.DataFrame(series_missing_seasonal,columns=['Series'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqBG4WPx4_qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_missing_season.fillna(-1.0).to_csv('miss_data.txt', header=None, index=None, sep='\\t', mode='a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCCtzu8Ma6US",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_original_season.to_excel('Seasonal Original.xlsx')\n",
        "df_missing_season.fillna(-1.0).to_excel('Seasonal Missing.xlsx')\n",
        "df_missing_season.interpolate(limit_direction='Both').to_excel('Seasonal Linear.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APKw-Kyg5Chy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LIMELSTM.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kqDQwHx5Jqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_lstm = pd.read_excel('/content/imputed_data_ for LSTM_new.xlsx')\n",
        "mse(df_original_season,df_lstm),mse(df_original_season,df_missing_season.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1HVjzpj7Owl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LIMEGRU.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYXLJyt37fPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_gru = pd.read_excel('/content/imputed_data_ for GRU.xlsx')\n",
        "mse(df_original_season,df_gru),mse(df_original_season,df_missing_season.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuejN_TV9wqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Hybrid.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-zNbIsc9_l5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_hyd = pd.read_excel('/content/imputed_data_ for Hybrid.xlsx')\n",
        "mse(df_original_season,df_hyd),mse(df_original_season,df_missing_season.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iphhbngCC5D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Residual.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGa1vSkTDED5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_res = pd.read_excel('/content/imputed_data_ for Residue.xlsx')\n",
        "mse(df_original_season,df_res),mse(df_original_season,df_missing_season.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22dCMPaQFTQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LIMEGRU.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlLL8psGF_Xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_gru1 = pd.read_excel('/content/imputed_data_ for GRU_new.xlsx')\n",
        "mse(df_original_season,df_gru1),mse(df_original_season,df_missing_season.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVmJsVUBGLmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LIMELSTM.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwE8YNBjGWTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_lstm1 = pd.read_excel('/content/imputed_data_ for LSTM.xlsx')\n",
        "mse(df_original_season,df_lstm1),mse(df_original_season,df_missing_season.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCWls1RkP19B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Residual.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht7vdsE3P_fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_res1 = pd.read_excel('/content/imputed_data_ for Residue_season.xlsx')\n",
        "mse(df_original_season,df_res1),mse(df_original_season,df_missing_season.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0vbxfJ1RumM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LIMEGRU.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhehljX3SfwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_gru2 = pd.read_excel('/content/imputed_data_ for GRU_season.xlsx')\n",
        "mse(df_original_season,df_gru2),mse(df_original_season,df_missing_season.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al4nAkkiTUnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Random.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc07M9M7VT8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_ran = pd.read_excel('/content/imputed_data_ for Random.xlsx')\n",
        "mse(df_original_season,df_ran),mse(df_original_season,df_missing_season.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7o3vCftXEmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_ran = pd.read_excel('/content/imputed_data_ for Random.xlsx')\n",
        "mse(df_original_season,df_ran),mse(df_original_season,df_missing_season.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q29n-NamZ2KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Hybrid_multiple.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23e6s7hycMe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_hmul = pd.read_excel('/content/imputed_data_ for Hybrid multiple.xlsx')\n",
        "mse(df_original_season,df_hmul),mse(df_original_season,df_missing_season.interpolate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zajdj1BWcibL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Random.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQGiZFeod0Rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_ran1 = pd.read_excel('/content/imputed_data_ for Random1.xlsx')\n",
        "mse(df_original_season,df_ran1),mse(df_original_season,df_missing_season.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbR-df9C9BET",
        "colab_type": "text"
      },
      "source": [
        "Trend and Seasonal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS_dbhJK9DXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slope = 0.05\n",
        "series_both = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, series_both)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg1x31j19MVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise = np.random.normal(0,10,1461)\n",
        "series_both_noise = series_both+noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BcULWVd9j8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "series_both_missing=np.copy(series_both_noise)\n",
        "for i in range(1,len(series_noise)):\n",
        "    if random.random()<= 0.5:\n",
        "        series_both_missing[i]=np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiU5lyc39rPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_series(time,series_both_missing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvIc4HQq90zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_original_both= pd.DataFrame(series_both_noise,columns=['Series'])\n",
        "df_missing_both= pd.DataFrame(series_both_missing,columns=['Series'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECUx2wL6-BFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_missing_both.fillna(-1.0).to_csv('miss_data2.txt',header=None, index=None, sep='\\t', mode='a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB8INQuKe4ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_original_both.to_excel('Both Original.xlsx')\n",
        "df_missing_both.fillna(-1.0).to_excel('Both Missing.xlsx')\n",
        "df_missing_both.interpolate(limit_direction='Both').to_excel('Both Linear.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXICwqj1-Nz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LIMELSTM.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-dzhLD3-Wrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_lstm_both = pd.read_excel('/content/imputed_data_ for LSTM_both.xlsx')\n",
        "mse(df_original_both,df_lstm_both),mse(df_original_both,df_missing_both.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkJApm5Z_Lpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LIMEGRU.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiCz2rtV_Vf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_gru_both = pd.read_excel('/content/imputed_data_ for GRU_both.xlsx')\n",
        "mse(df_original_both,df_gru_both),mse(df_original_both,df_missing_both.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJgY47BHAHpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Hybrid.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcWmDw7cAUa9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_hyd_both = pd.read_excel('/content/imputed_data_ for Hybrid_both.xlsx')\n",
        "mse(df_original_both,df_hyd_both),mse(df_original_both,df_missing_both.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I3qJ7v_SYlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Hybrid_multiple.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o33ijYfSpPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_hym_both = pd.read_excel('/content/imputed_data_ for Hybrid multiple Both.xlsx')\n",
        "mse(df_original_both,df_hym_both),mse(df_original_both,df_missing_both.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QonuwnbsgXCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Residual.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iNNKaXggqYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_res_both = pd.read_excel('/content/imputed_data_ for Residue_both.xlsx')\n",
        "mse(df_original_both,df_res_both),mse(df_original_both,df_missing_both.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C61wF1SioXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python GRU_Deep.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-fj_G2-i2yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_grd_both = pd.read_excel('/content/imputed_data_ for GRU_deep_both.xlsx')\n",
        "mse(df_original_both,df_grd_both),mse(df_original_both,df_missing_both.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsZKVKL7jZoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Random.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbxaVWC2jdDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_lgg_both = pd.read_excel('/content/imputed_data_ for lstm-gru-gru_both.xlsx')\n",
        "mse(df_original_both,df_lgg_both),mse(df_original_both,df_missing_both.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiCXxi3h6erk",
        "colab_type": "text"
      },
      "source": [
        "Random Time Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzyt9BG86ivh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "time = np.arange(4 * 365 + 1)+50\n",
        "series_ran = np.random.normal(50,10,1461)\n",
        "plot_series(time,series_ran)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df0N86_-XGsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "series_missing_ran=np.copy(series_ran)\n",
        "for i in range(1,len(series_ran)):\n",
        "    if random.random()<= 0.5:\n",
        "        series_missing_ran[i]=np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h79KSpoaXXlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_series(time,series_missing_ran)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70qKyb8xXbLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.count_nonzero(np.isnan(series_ran)),np.count_nonzero(np.isnan(series_missing_ran))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuRv7TbzXq5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_original_ran= pd.DataFrame(series_ran,columns=['Series'])\n",
        "df_missing_ran= pd.DataFrame(series_missing_ran,columns=['Series'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb3AHr8AX32F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_original_ran.to_excel('Random Original.xlsx')\n",
        "df_missing_ran.fillna(-1.0).to_excel('Random Missing.xlsx')\n",
        "df_missing_ran.fillna(-1.0).to_csv('miss_data.txt', header=None, index=None, sep='\\t', mode='a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFPV3jAGYgUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LIMELSTM.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJWOJ6Z-ZLS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_lstm = pd.read_excel('/content/imputed_data_ for LSTM_Random.xlsx')\n",
        "mse(df_original_ran,df_lstm),mse(df_original_ran,df_missing_ran.interpolate(limit_direction='both'))\n",
        "mae(df_original_ran,df_lstm),mae(df_original_ran,df_missing_ran.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIQj2DYiaAoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LIMEGRU.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKZmi5yzaoI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_gru = pd.read_excel('/content/imputed_data_ for GRU_Random.xlsx')\n",
        "mse(df_original_ran,df_gru),mse(df_original_ran,df_missing_ran.interpolate(limit_direction='both'))\n",
        "mae(df_original_ran,df_gru),mae(df_original_ran,df_missing_ran.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2yQbA1hfKEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Hybrid.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-hPeSeNfcZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_hyd = pd.read_excel('/content/imputed_data_ for Hybrid_Random.xlsx')\n",
        "mse(df_original_ran,df_hyd),mse(df_original_ran,df_missing_ran.interpolate(limit_direction='both'))\n",
        "mae(df_original_ran,df_hyd),mae(df_original_ran,df_missing_ran.interpolate(limit_direction='both'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diJzg_wXqjpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Hybrid_multiple.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elrm8hyVquZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_hym = pd.read_excel('/content/imputed_data_ for Hybrid multiple Random.xlsx')\n",
        "mse(df_original_ran,df_hym),mse(df_original_ran,df_missing_ran.interpolate(limit_direction='both'))\n",
        "print(mae(df_original_ran,df_hym),mae(df_original_ran,df_missing_ran.interpolate(limit_direction='both')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKhzdshcq7NH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python GRU_Deep.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkTUpExCrE4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_grd = pd.read_excel('/content/imputed_data_ for GRU_deep_Random.xlsx')\n",
        "mse(df_original_ran,df_grd),mse(df_original_ran,df_missing_ran.interpolate(limit_direction='both'))\n",
        "print(mae(df_original_ran,df_grd),mae(df_original_ran,df_missing_ran.interpolate(limit_direction='both')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se7-Z6_irp5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Random.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUOTgn-erMeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "df_lgg = pd.read_excel('/content/imputed_data_ for lstm-gru-gru-Random.xlsx')\n",
        "mse(df_original_ran,df_lgg),mse(df_original_ran,df_missing_ran.interpolate(limit_direction='both'))\n",
        "print(mae(df_original_ran,df_lgg),mae(df_original_ran,df_missing_ran.interpolate(limit_direction='both')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plr12Bs2roJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Residual.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0HZJup4r2Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "df_res = pd.read_excel('/content/imputed_data_ for Residue_Random.xlsx')\n",
        "print(mse(df_original_ran,df_res),mse(df_original_ran,df_missing_ran.interpolate(limit_direction='both')))\n",
        "print(mae(df_original_ran,df_res),mae(df_original_ran,df_missing_ran.interpolate(limit_direction='both')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0tixKmG0wqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_missing_ran.interpolate(limit_direction='both').to_excel('Random Linear.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywL1hQh21Sq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "ecal = pd.read_excel('/content/MSE for python.xlsx')\n",
        "ecal.head()\n",
        "for i in ecal.columns:\n",
        "    print('the mse for',i,'is:',mse(ecal['Original'],ecal[i]))\n",
        "print('------------------')\n",
        "for i in ecal.columns:\n",
        "    print('the mae for',i,'is:',mae(ecal['Original'],ecal[i]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YImN6PyYRvwH",
        "colab_type": "text"
      },
      "source": [
        "# Ensembling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1O6-poSzxpb",
        "colab_type": "text"
      },
      "source": [
        "Trend Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ejhWWBdDmZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_excel('/content/Trend Missing.xlsx')\n",
        "df.replace(-1.0,np.nan,inplace=True)\n",
        "df.head()\n",
        "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUXD57PNy5cR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "series_missing=np.copy(df.values)\n",
        "for i in range(1,len(df.values)):\n",
        "    if random.random()<= 0.10:\n",
        "        series_missing[i]=np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYin_R47zxJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_missing = pd.DataFrame(series_missing,columns=['Series'])\n",
        "print(df_missing.isnull().sum())\n",
        "print(df.shape,df_missing.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj7wECW1z8QT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_missing.fillna(-1.0).to_excel('Trend Further missing.xlsx')\n",
        "df_missing.fillna(-1.0).to_csv('miss_data.txt', header=None, index=None, sep='\\t', mode='a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGMxmOXl2GnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LIMEGRU.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLKHZ92Q2NXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Residual.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTsfsT_43Fjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mdf = pd.read_excel('/content/ML Ensemble Training.xlsx')\n",
        "mdf.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufk9_t-F5vMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = mdf[['GRU','Residual']].values\n",
        "y_train=mdf[['Original']].values\n",
        "type(x_train),x_train.shape,type(y_train),y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GnVJxfi6JA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "import sklearn.model_selection\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "# import autosklearn.regression\n",
        "from sklearn import ensemble\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEqpBEzi7wJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbr = ensemble.GradientBoostingRegressor()\n",
        "clf = SVR(kernel='linear')\n",
        "clf.fit(x_train,y_train)\n",
        "gbr.fit(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeUS0vmJ6QxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytest = pd.read_excel('/content/y_test.xlsx').values\n",
        "xtest = pd.read_excel('/content/x_test.xlsx').values\n",
        "type(ytest),ytest.shape,type(xtest),xtest.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw6Je9iA6WJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = clf.predict(xtest)\n",
        "predictions2 = gbr.predict(xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DDkXTz36iei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse(ytest,predictions),mae(ytest,predictions),mse(ytest,predictions2),mae(ytest,predictions2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBnnMvtBz0mX",
        "colab_type": "text"
      },
      "source": [
        "Seasonal Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzpigavg9LMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_excel('/content/Seasonal Missing.xlsx')\n",
        "df.replace(-1.0,np.nan,inplace=True)\n",
        "print(df.head())\n",
        "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4t6WmHr0G_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "series_missing=np.copy(df.values)\n",
        "for i in range(1,len(df.values)):\n",
        "    if random.random()<= 0.10:\n",
        "        series_missing[i]=np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShwEufdk0Q66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_missing = pd.DataFrame(series_missing,columns=['Series'])\n",
        "print(df_missing.isnull().sum())\n",
        "print(df.shape,df_missing.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GseNMl6X0ThH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_missing.fillna(-1.0).to_excel('Seasonal Further missing.xlsx')\n",
        "df_missing.fillna(-1.0).to_csv('miss_data.txt', header=None, index=None, sep='\\t', mode='a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JspFt8Fp0YEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Random.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMp1aRDR0647",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python Residual.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CYj1c233w3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mdf = pd.read_excel('/content/ML Ensemble Training.xlsx')\n",
        "print(mdf.head())\n",
        "x_train = mdf[['LSTM GRU GRU','Residual']].values\n",
        "y_train=mdf[['Orignial']].values\n",
        "type(x_train),x_train.shape,type(y_train),y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC2nlzfL63xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytest = pd.read_excel('/content/y_test.xlsx').values\n",
        "xtest = pd.read_excel('/content/x_test.xlsx').values\n",
        "type(ytest),ytest.shape,type(xtest),xtest.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i49bNG-k5UdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbr = ensemble.GradientBoostingRegressor()\n",
        "clf = SVR(kernel='linear')\n",
        "clf.fit(x_train,y_train)\n",
        "gbr.fit(x_train,y_train)\n",
        "predictions = clf.predict(xtest)\n",
        "predictions2 = gbr.predict(xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eaOTYbW6o89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse(ytest,predictions),mae(ytest,predictions),mse(ytest,predictions2),mae(ytest,predictions2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oI96i3K69Pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression().fit(x_train, y_train)\n",
        "print(reg.score(x_train, y_train))\n",
        "\n",
        "# reg.coef_\n",
        "\n",
        "# reg.intercept_\n",
        "\n",
        "lr_pred=reg.predict(xtest)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0ZwV3Vm7e7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse(ytest,lr_pred),mae(ytest,lr_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMTSrYrZ7jNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "model = AdaBoostRegressor()\n",
        "model.fit(x_train, y_train)\n",
        "# model.score(x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8h9czXZ84Ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse(ytest,model.predict(xtest)),mae(ytest,model.predict(xtest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8r6nGsr8_ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "model1=xgb.XGBRegressor()\n",
        "model1.fit(x_train, y_train)\n",
        "# model.score(x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdVaFc6O9cz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse(ytest,model1.predict(xtest)),mae(ytest,model1.predict(xtest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIDJbuLT9fDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "neigh = KNeighborsRegressor(n_neighbors=30)\n",
        "neigh.fit(x_train, y_train)\n",
        "mse(ytest,neigh.predict(xtest)),mae(ytest,neigh.predict(xtest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O8jbsWl-fp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "reg = linear_model.Lasso()\n",
        "reg.fit(x_train, y_train)\n",
        "mse(ytest,reg.predict(xtest)),mae(ytest,reg.predict(xtest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhenQ3mS-8Iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg = (reg.predict(xtest).reshape(-1,1)+lr_pred.reshape(-1,1)+predictions.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCZtkZfk_V3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIsH72E4_YAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg=avg/3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHHt1U2b_0Fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg.shape,ytest.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W6qY-pR_0_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mae(ytest,avg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IjiTI-FTcnT",
        "colab_type": "text"
      },
      "source": [
        "Both Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQHynfnb_45N",
        "colab_type": "code",
        "outputId": "e4acfe72-2877-42fd-cf01-9cc7c77af765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "df = pd.read_excel('/content/Both Missing.xlsx')\n",
        "df.replace(-1.0,np.nan,inplace=True)\n",
        "print(df.head())\n",
        "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0      Series\n",
            "0           0  236.841804\n",
            "1           1         NaN\n",
            "2           2         NaN\n",
            "3           3         NaN\n",
            "4           4         NaN\n",
            "Series    718\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdxUvrl_UEOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "series_missing=np.copy(df.values)\n",
        "for i in range(1,len(df.values)):\n",
        "    if random.random()<= 0.10:\n",
        "        series_missing[i]=np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF7ya_73UJB8",
        "colab_type": "code",
        "outputId": "d489c697-e5b8-4775-8e9b-61d989436faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df_missing = pd.DataFrame(series_missing,columns=['Series'])\n",
        "print(df_missing.isnull().sum())\n",
        "print(df.shape,df_missing.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Series    781\n",
            "dtype: int64\n",
            "(1461, 1) (1461, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S8txN7UUMCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_missing.fillna(-1.0).to_excel('Both Further missing.xlsx')\n",
        "df_missing.fillna(-1.0).to_csv('miss_data.txt', header=None, index=None, sep='\\t', mode='a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UwFQOGfUQ1a",
        "colab_type": "code",
        "outputId": "12ff04a2-4215-42ad-9072-691008c74f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python LIMEGRU.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From LIMEGRU.py:142: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "I0222 23:57:22.929220 139884865714048 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:From LIMEGRU.py:114: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0222 23:57:22.937943 139884865714048 module_wrapper.py:139] From LIMEGRU.py:114: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From LIMEGRU.py:117: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0222 23:57:22.938246 139884865714048 module_wrapper.py:139] From LIMEGRU.py:117: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-02-22 23:57:22.956192: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-02-22 23:57:22.959787: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3200bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-22 23:57:22.959843: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-22 23:57:22.994326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-22 23:57:23.065934: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-02-22 23:57:23.066005: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (3114d6793ca9): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From LIMEGRU.py:120: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0222 23:57:23.066705 139884865714048 module_wrapper.py:139] From LIMEGRU.py:120: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From LIMEGRU.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0222 23:57:23.067153 139884865714048 module_wrapper.py:139] From LIMEGRU.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From LIMEGRU.py:32: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0222 23:57:23.068780 139884865714048 deprecation.py:323] From LIMEGRU.py:32: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From LIMEGRU.py:33: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0222 23:57:23.070953 139884865714048 deprecation.py:323] From LIMEGRU.py:33: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "W0222 23:57:23.103085 139884865714048 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0222 23:57:23.111507 139884865714048 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0222 23:57:23.121875 139884865714048 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From LIMEGRU.py:41: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0222 23:57:23.137850 139884865714048 module_wrapper.py:139] From LIMEGRU.py:41: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From LIMEGRU.py:49: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0222 23:57:23.144672 139884865714048 deprecation.py:323] From LIMEGRU.py:49: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From LIMEGRU.py:70: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0222 23:57:23.852163 139884865714048 module_wrapper.py:139] From LIMEGRU.py:70: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From LIMEGRU.py:73: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "W0222 23:57:26.314041 139884865714048 module_wrapper.py:139] From LIMEGRU.py:73: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "W0222 23:57:26.315102 139884865714048 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "Number of iterations: 0\n",
            "(1460, 1)\n",
            "Number of iterations: 1\n",
            "(1460, 1)\n",
            "Number of iterations: 2\n",
            "(1460, 1)\n",
            "Number of iterations: 3\n",
            "(1460, 1)\n",
            "Number of iterations: 4\n",
            "(1460, 1)\n",
            "Number of iterations: 5\n",
            "(1460, 1)\n",
            "RMSE: 0.1907581379101012\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 6\n",
            "(1460, 1)\n",
            "RMSE: 0.19651206139443503\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 7\n",
            "(1460, 1)\n",
            "RMSE: 0.2000904460915537\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 8\n",
            "(1460, 1)\n",
            "RMSE: 0.19606608024697483\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 9\n",
            "(1460, 1)\n",
            "RMSE: 0.20234163667555088\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 10\n",
            "(1460, 1)\n",
            "RMSE: 0.19682569518565315\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 11\n",
            "(1460, 1)\n",
            "RMSE: 0.2119151045381133\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 12\n",
            "(1460, 1)\n",
            "RMSE: 0.18455562567435502\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 13\n",
            "(1460, 1)\n",
            "RMSE: 0.18927998951785802\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 14\n",
            "(1460, 1)\n",
            "RMSE: 0.19080832583724416\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 15\n",
            "(1460, 1)\n",
            "RMSE: 0.1900246418919798\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 16\n",
            "(1460, 1)\n",
            "RMSE: 0.19230537145009755\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 17\n",
            "(1460, 1)\n",
            "RMSE: 0.18937609988547366\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 18\n",
            "(1460, 1)\n",
            "RMSE: 0.19163997751911077\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 19\n",
            "(1460, 1)\n",
            "RMSE: 0.19214160569393104\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 20\n",
            "(1460, 1)\n",
            "RMSE: 0.19377716190793734\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 21\n",
            "(1460, 1)\n",
            "RMSE: 0.22211996918036228\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 22\n",
            "(1460, 1)\n",
            "RMSE: 0.20754263045627352\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 23\n",
            "(1460, 1)\n",
            "RMSE: 0.19973701298538502\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 24\n",
            "(1460, 1)\n",
            "RMSE: 0.19190824087430886\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 25\n",
            "(1460, 1)\n",
            "RMSE: 0.1883774807590646\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 26\n",
            "(1460, 1)\n",
            "RMSE: 0.18729389791354614\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 27\n",
            "(1460, 1)\n",
            "RMSE: 0.1873212632843288\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 28\n",
            "(1460, 1)\n",
            "RMSE: 0.18822951374595345\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 29\n",
            "(1460, 1)\n",
            "RMSE: 0.18707326911196412\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 30\n",
            "(1460, 1)\n",
            "RMSE: 0.18671993471069934\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 31\n",
            "(1460, 1)\n",
            "RMSE: 0.18958417935900124\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 32\n",
            "(1460, 1)\n",
            "RMSE: 0.1796659829581091\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 33\n",
            "(1460, 1)\n",
            "RMSE: 0.17863315270783864\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 34\n",
            "(1460, 1)\n",
            "RMSE: 0.17841686688256872\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 35\n",
            "(1460, 1)\n",
            "RMSE: 0.177924173120378\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 36\n",
            "(1460, 1)\n",
            "RMSE: 0.1770464002004294\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 37\n",
            "(1460, 1)\n",
            "RMSE: 0.17584121603836164\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 38\n",
            "(1460, 1)\n",
            "RMSE: 0.17416785335358834\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 39\n",
            "(1460, 1)\n",
            "RMSE: 0.171838685722794\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 40\n",
            "(1460, 1)\n",
            "RMSE: 0.1643745726560364\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 41\n",
            "(1460, 1)\n",
            "RMSE: 0.18482214520612864\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 42\n",
            "(1460, 1)\n",
            "RMSE: 0.13496067308160756\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 43\n",
            "(1460, 1)\n",
            "RMSE: 0.12785902078092862\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 44\n",
            "(1460, 1)\n",
            "RMSE: 0.12317967560378536\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 45\n",
            "(1460, 1)\n",
            "RMSE: 0.11774584745457412\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 46\n",
            "(1460, 1)\n",
            "RMSE: 0.11413327356210698\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 47\n",
            "(1460, 1)\n",
            "RMSE: 0.10964061294642342\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 48\n",
            "(1460, 1)\n",
            "RMSE: 0.10437149432245844\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 49\n",
            "(1460, 1)\n",
            "RMSE: 0.10075032538088141\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 50\n",
            "(1460, 1)\n",
            "RMSE: 0.0966531637740285\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 51\n",
            "(1460, 1)\n",
            "RMSE: 0.09679561452914533\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 52\n",
            "(1460, 1)\n",
            "RMSE: 0.087074831267593\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 53\n",
            "(1460, 1)\n",
            "RMSE: 0.08427747541115875\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 54\n",
            "(1460, 1)\n",
            "RMSE: 0.08297117454121071\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 55\n",
            "(1460, 1)\n",
            "RMSE: 0.08202557147239271\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 56\n",
            "(1460, 1)\n",
            "RMSE: 0.081323135343266\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 57\n",
            "(1460, 1)\n",
            "RMSE: 0.08078665910519443\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 58\n",
            "(1460, 1)\n",
            "RMSE: 0.08036899735898242\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 59\n",
            "(1460, 1)\n",
            "RMSE: 0.08003342418388475\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 60\n",
            "(1460, 1)\n",
            "RMSE: 0.07975311020422911\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 61\n",
            "(1460, 1)\n",
            "RMSE: 0.07960335549928221\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 62\n",
            "(1460, 1)\n",
            "RMSE: 0.07617659673425771\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 63\n",
            "(1460, 1)\n",
            "RMSE: 0.0763755885250505\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 64\n",
            "(1460, 1)\n",
            "RMSE: 0.0762856923662857\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 65\n",
            "(1460, 1)\n",
            "RMSE: 0.07627370335150456\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 66\n",
            "(1460, 1)\n",
            "RMSE: 0.07626887714667975\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 67\n",
            "(1460, 1)\n",
            "RMSE: 0.07627232340966708\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 68\n",
            "(1460, 1)\n",
            "RMSE: 0.07627887423752404\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 69\n",
            "(1460, 1)\n",
            "RMSE: 0.07628593851607775\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 70\n",
            "(1460, 1)\n",
            "RMSE: 0.07629194765267772\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 71\n",
            "(1460, 1)\n",
            "RMSE: 0.07629065213457376\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 72\n",
            "(1460, 1)\n",
            "RMSE: 0.07522052388496617\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 73\n",
            "(1460, 1)\n",
            "RMSE: 0.07535399538050559\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 74\n",
            "(1460, 1)\n",
            "RMSE: 0.07533233254231358\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 75\n",
            "(1460, 1)\n",
            "RMSE: 0.07534078586340408\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 76\n",
            "(1460, 1)\n",
            "RMSE: 0.07534121464305511\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 77\n",
            "(1460, 1)\n",
            "RMSE: 0.0753425571493185\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 78\n",
            "(1460, 1)\n",
            "RMSE: 0.07534320357661635\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 79\n",
            "(1460, 1)\n",
            "RMSE: 0.07534371982223094\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 80\n",
            "(1460, 1)\n",
            "RMSE: 0.07534407277275165\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 81\n",
            "(1460, 1)\n",
            "RMSE: 0.07530887410682842\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 82\n",
            "(1460, 1)\n",
            "RMSE: 0.07500191370888959\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 83\n",
            "(1460, 1)\n",
            "RMSE: 0.07501974446790916\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 84\n",
            "(1460, 1)\n",
            "RMSE: 0.07501961316633315\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 85\n",
            "(1460, 1)\n",
            "RMSE: 0.07501926051796858\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 86\n",
            "(1460, 1)\n",
            "RMSE: 0.0750184218037203\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 87\n",
            "(1460, 1)\n",
            "RMSE: 0.07501719079440282\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 88\n",
            "(1460, 1)\n",
            "RMSE: 0.07501568932931815\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 89\n",
            "(1460, 1)\n",
            "RMSE: 0.07501398666801563\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 90\n",
            "(1460, 1)\n",
            "RMSE: 0.07501212558119437\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 91\n",
            "(1460, 1)\n",
            "RMSE: 0.07496644799603293\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 92\n",
            "(1460, 1)\n",
            "RMSE: 0.07487243818369323\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 93\n",
            "(1460, 1)\n",
            "RMSE: 0.0748664579994743\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 94\n",
            "(1460, 1)\n",
            "RMSE: 0.07486519531188475\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 95\n",
            "(1460, 1)\n",
            "RMSE: 0.07486408769787628\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 96\n",
            "(1460, 1)\n",
            "RMSE: 0.07486291823217958\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 97\n",
            "(1460, 1)\n",
            "RMSE: 0.07486162873856403\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 98\n",
            "(1460, 1)\n",
            "RMSE: 0.0748602108033193\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 99\n",
            "(1460, 1)\n",
            "RMSE: 0.07485866696916421\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 100\n",
            "(1460, 1)\n",
            "RMSE: 0.07485701128185852\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 101\n",
            "(1460, 1)\n",
            "RMSE: 0.07482163855234972\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 102\n",
            "(1460, 1)\n",
            "RMSE: 0.07479541722963182\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 103\n",
            "(1460, 1)\n",
            "RMSE: 0.0747869632789756\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 104\n",
            "(1460, 1)\n",
            "RMSE: 0.07478412022275399\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 105\n",
            "(1460, 1)\n",
            "RMSE: 0.07478269684840091\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 106\n",
            "(1460, 1)\n",
            "RMSE: 0.07478160052688029\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 107\n",
            "(1460, 1)\n",
            "RMSE: 0.0747805630526539\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 108\n",
            "(1460, 1)\n",
            "RMSE: 0.07477948627390156\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 109\n",
            "(1460, 1)\n",
            "RMSE: 0.07477838172702275\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 110\n",
            "(1460, 1)\n",
            "RMSE: 0.07477721075222625\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 111\n",
            "(1460, 1)\n",
            "RMSE: 0.07475482004003979\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 112\n",
            "(1460, 1)\n",
            "RMSE: 0.07474790431705215\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 113\n",
            "(1460, 1)\n",
            "RMSE: 0.07474366775056791\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 114\n",
            "(1460, 1)\n",
            "RMSE: 0.07474119352629734\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 115\n",
            "(1460, 1)\n",
            "RMSE: 0.07473961171968205\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 116\n",
            "(1460, 1)\n",
            "RMSE: 0.07473847840224017\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 117\n",
            "(1460, 1)\n",
            "RMSE: 0.0747375710778649\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 118\n",
            "(1460, 1)\n",
            "RMSE: 0.07473676210921126\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 119\n",
            "(1460, 1)\n",
            "RMSE: 0.07473599952110788\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 120\n",
            "(1460, 1)\n",
            "RMSE: 0.07473525505085818\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 121\n",
            "(1460, 1)\n",
            "RMSE: 0.0747223906135462\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 122\n",
            "(1460, 1)\n",
            "RMSE: 0.07472051002570694\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 123\n",
            "(1460, 1)\n",
            "RMSE: 0.07471892208990581\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 124\n",
            "(1460, 1)\n",
            "RMSE: 0.07471767515815585\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 125\n",
            "(1460, 1)\n",
            "RMSE: 0.07471666920013365\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 126\n",
            "(1460, 1)\n",
            "RMSE: 0.07471582706631426\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 127\n",
            "(1460, 1)\n",
            "RMSE: 0.07471512163813722\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 128\n",
            "(1460, 1)\n",
            "RMSE: 0.07471448437207\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 129\n",
            "(1460, 1)\n",
            "RMSE: 0.07471389662502277\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 130\n",
            "(1460, 1)\n",
            "RMSE: 0.07471335584428042\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 131\n",
            "(1460, 1)\n",
            "RMSE: 0.0747062951576402\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 132\n",
            "(1460, 1)\n",
            "RMSE: 0.07470568760917926\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 133\n",
            "(1460, 1)\n",
            "RMSE: 0.07470509514486783\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 134\n",
            "(1460, 1)\n",
            "RMSE: 0.07470455985458001\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 135\n",
            "(1460, 1)\n",
            "RMSE: 0.07470406950207989\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 136\n",
            "(1460, 1)\n",
            "RMSE: 0.07470361852386347\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 137\n",
            "(1460, 1)\n",
            "RMSE: 0.07470319585741872\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 138\n",
            "(1460, 1)\n",
            "RMSE: 0.07470279972694115\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 139\n",
            "(1460, 1)\n",
            "RMSE: 0.07470242889776282\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 140\n",
            "(1460, 1)\n",
            "RMSE: 0.07470207625085593\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 141\n",
            "(1460, 1)\n",
            "RMSE: 0.07469831309025805\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 142\n",
            "(1460, 1)\n",
            "RMSE: 0.07469806589040197\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 143\n",
            "(1460, 1)\n",
            "RMSE: 0.07469781510766459\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 144\n",
            "(1460, 1)\n",
            "RMSE: 0.07469757985167369\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 145\n",
            "(1460, 1)\n",
            "RMSE: 0.07469734968973477\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 146\n",
            "(1460, 1)\n",
            "RMSE: 0.07469712770789315\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 147\n",
            "(1460, 1)\n",
            "RMSE: 0.07469691360028928\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 148\n",
            "(1460, 1)\n",
            "RMSE: 0.07469670338093115\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 149\n",
            "(1460, 1)\n",
            "RMSE: 0.07469649884077348\n",
            "The Learning rate is: 9.765625e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70dY95W8VVqG",
        "colab_type": "code",
        "outputId": "a674fbc8-f565-4fb4-9cd4-ba8f7ab0c37e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python Hybrid.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From Hybrid.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "I0222 23:59:55.608554 139819253102464 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:From Hybrid.py:115: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0222 23:59:55.615999 139819253102464 module_wrapper.py:139] From Hybrid.py:115: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From Hybrid.py:118: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0222 23:59:55.616322 139819253102464 module_wrapper.py:139] From Hybrid.py:118: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-02-22 23:59:55.621507: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-02-22 23:59:55.621753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2e6cbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-22 23:59:55.621786: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-22 23:59:55.624146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-22 23:59:55.626112: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-02-22 23:59:55.626154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (3114d6793ca9): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From Hybrid.py:121: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0222 23:59:55.626788 139819253102464 module_wrapper.py:139] From Hybrid.py:121: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From Hybrid.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0222 23:59:55.627374 139819253102464 module_wrapper.py:139] From Hybrid.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From Hybrid.py:32: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0222 23:59:55.629257 139819253102464 deprecation.py:323] From Hybrid.py:32: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From Hybrid.py:33: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0222 23:59:55.631506 139819253102464 deprecation.py:323] From Hybrid.py:33: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From Hybrid.py:34: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0222 23:59:55.632055 139819253102464 deprecation.py:323] From Hybrid.py:34: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "W0222 23:59:55.651414 139819253102464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0222 23:59:55.659500 139819253102464 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0222 23:59:55.681477 139819253102464 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From Hybrid.py:42: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0222 23:59:55.705971 139819253102464 module_wrapper.py:139] From Hybrid.py:42: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From Hybrid.py:50: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0222 23:59:55.712762 139819253102464 deprecation.py:323] From Hybrid.py:50: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From Hybrid.py:71: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0222 23:59:56.835719 139819253102464 module_wrapper.py:139] From Hybrid.py:71: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From Hybrid.py:74: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "W0223 00:00:00.601211 139819253102464 module_wrapper.py:139] From Hybrid.py:74: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "W0223 00:00:00.602327 139819253102464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "Number of iterations: 0\n",
            "(1460, 1)\n",
            "Number of iterations: 1\n",
            "(1460, 1)\n",
            "Number of iterations: 2\n",
            "(1460, 1)\n",
            "Number of iterations: 3\n",
            "(1460, 1)\n",
            "Number of iterations: 4\n",
            "(1460, 1)\n",
            "Number of iterations: 5\n",
            "(1460, 1)\n",
            "RMSE: 0.19800593852928716\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 6\n",
            "(1460, 1)\n",
            "RMSE: 0.2110301507954286\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 7\n",
            "(1460, 1)\n",
            "RMSE: 0.19407556568695739\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 8\n",
            "(1460, 1)\n",
            "RMSE: 0.20570877268550086\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 9\n",
            "(1460, 1)\n",
            "RMSE: 0.18537493247505893\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 10\n",
            "(1460, 1)\n",
            "RMSE: 0.20799331652031733\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 11\n",
            "(1460, 1)\n",
            "RMSE: 0.19353120666405615\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 12\n",
            "(1460, 1)\n",
            "RMSE: 0.21475094177798024\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 13\n",
            "(1460, 1)\n",
            "RMSE: 0.21868499507331576\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 14\n",
            "(1460, 1)\n",
            "RMSE: 0.21226378914186203\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 15\n",
            "(1460, 1)\n",
            "RMSE: 0.20893116631675332\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 16\n",
            "(1460, 1)\n",
            "RMSE: 0.2203585207618485\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 17\n",
            "(1460, 1)\n",
            "RMSE: 0.2280601919788729\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 18\n",
            "(1460, 1)\n",
            "RMSE: 0.21462076009531217\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 19\n",
            "(1460, 1)\n",
            "RMSE: 0.2016197048449787\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 20\n",
            "(1460, 1)\n",
            "RMSE: 0.21315617861156178\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 21\n",
            "(1460, 1)\n",
            "RMSE: 0.20745394234273234\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 22\n",
            "(1460, 1)\n",
            "RMSE: 0.19137119677278022\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 23\n",
            "(1460, 1)\n",
            "RMSE: 0.1878538756812181\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 24\n",
            "(1460, 1)\n",
            "RMSE: 0.18761178305552167\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 25\n",
            "(1460, 1)\n",
            "RMSE: 0.1875156360291233\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 26\n",
            "(1460, 1)\n",
            "RMSE: 0.18741015513499046\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 27\n",
            "(1460, 1)\n",
            "RMSE: 0.18734387409132475\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 28\n",
            "(1460, 1)\n",
            "RMSE: 0.18724108459071376\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 29\n",
            "(1460, 1)\n",
            "RMSE: 0.18723625446134845\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 30\n",
            "(1460, 1)\n",
            "RMSE: 0.18703802961241575\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 31\n",
            "(1460, 1)\n",
            "RMSE: 0.18664346253908715\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 32\n",
            "(1460, 1)\n",
            "RMSE: 0.18342726210942878\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 33\n",
            "(1460, 1)\n",
            "RMSE: 0.1828481933177168\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 34\n",
            "(1460, 1)\n",
            "RMSE: 0.18259297968494326\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 35\n",
            "(1460, 1)\n",
            "RMSE: 0.18244172345180193\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 36\n",
            "(1460, 1)\n",
            "RMSE: 0.18231056166538032\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 37\n",
            "(1460, 1)\n",
            "RMSE: 0.1821615787491393\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 38\n",
            "(1460, 1)\n",
            "RMSE: 0.18197414987997235\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 39\n",
            "(1460, 1)\n",
            "RMSE: 0.18173732708950757\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 40\n",
            "(1460, 1)\n",
            "RMSE: 0.18145579056154718\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 41\n",
            "(1460, 1)\n",
            "RMSE: 0.1792668714003616\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 42\n",
            "(1460, 1)\n",
            "RMSE: 0.16990764318346205\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 43\n",
            "(1460, 1)\n",
            "RMSE: 0.1746730651183742\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 44\n",
            "(1460, 1)\n",
            "RMSE: 0.15584838126629263\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 45\n",
            "(1460, 1)\n",
            "RMSE: 0.1746506353748149\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 46\n",
            "(1460, 1)\n",
            "RMSE: 0.18875669657576025\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 47\n",
            "(1460, 1)\n",
            "RMSE: 0.1628333951635023\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 48\n",
            "(1460, 1)\n",
            "RMSE: 0.1385713698740441\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 49\n",
            "(1460, 1)\n",
            "RMSE: 0.12686964880630888\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 50\n",
            "(1460, 1)\n",
            "RMSE: 0.11580130618392136\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 51\n",
            "(1460, 1)\n",
            "RMSE: 0.1180389736400279\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 52\n",
            "(1460, 1)\n",
            "RMSE: 0.09749234821988806\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 53\n",
            "(1460, 1)\n",
            "RMSE: 0.095156339815124\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 54\n",
            "(1460, 1)\n",
            "RMSE: 0.09362202168904345\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 55\n",
            "(1460, 1)\n",
            "RMSE: 0.09219475051778513\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 56\n",
            "(1460, 1)\n",
            "RMSE: 0.09090432645588566\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 57\n",
            "(1460, 1)\n",
            "RMSE: 0.08970620757482564\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 58\n",
            "(1460, 1)\n",
            "RMSE: 0.08854386106206236\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 59\n",
            "(1460, 1)\n",
            "RMSE: 0.08738393094917879\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 60\n",
            "(1460, 1)\n",
            "RMSE: 0.0862346228764355\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 61\n",
            "(1460, 1)\n",
            "RMSE: 0.08432649769860794\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 62\n",
            "(1460, 1)\n",
            "RMSE: 0.07878144486478594\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 63\n",
            "(1460, 1)\n",
            "RMSE: 0.07877653155930558\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 64\n",
            "(1460, 1)\n",
            "RMSE: 0.07853634046969231\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 65\n",
            "(1460, 1)\n",
            "RMSE: 0.07836505330182\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 66\n",
            "(1460, 1)\n",
            "RMSE: 0.07823411486735297\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 67\n",
            "(1460, 1)\n",
            "RMSE: 0.07813673340158128\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 68\n",
            "(1460, 1)\n",
            "RMSE: 0.07806564407375456\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 69\n",
            "(1460, 1)\n",
            "RMSE: 0.0780139748671313\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 70\n",
            "(1460, 1)\n",
            "RMSE: 0.07797590879166255\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 71\n",
            "(1460, 1)\n",
            "RMSE: 0.07741364971384507\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 72\n",
            "(1460, 1)\n",
            "RMSE: 0.0757788204372257\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 73\n",
            "(1460, 1)\n",
            "RMSE: 0.07601465101476693\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 74\n",
            "(1460, 1)\n",
            "RMSE: 0.07597330212197326\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 75\n",
            "(1460, 1)\n",
            "RMSE: 0.07599527829768565\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 76\n",
            "(1460, 1)\n",
            "RMSE: 0.07600543558737988\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 77\n",
            "(1460, 1)\n",
            "RMSE: 0.07601919508103917\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 78\n",
            "(1460, 1)\n",
            "RMSE: 0.07603248725695828\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 79\n",
            "(1460, 1)\n",
            "RMSE: 0.07604573778178624\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 80\n",
            "(1460, 1)\n",
            "RMSE: 0.0760585139009127\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 81\n",
            "(1460, 1)\n",
            "RMSE: 0.07579483960525094\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 82\n",
            "(1460, 1)\n",
            "RMSE: 0.0753139204589682\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 83\n",
            "(1460, 1)\n",
            "RMSE: 0.07536542101784957\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 84\n",
            "(1460, 1)\n",
            "RMSE: 0.07537091385690922\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 85\n",
            "(1460, 1)\n",
            "RMSE: 0.0753805112079711\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 86\n",
            "(1460, 1)\n",
            "RMSE: 0.07538896861253595\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 87\n",
            "(1460, 1)\n",
            "RMSE: 0.0753967376837306\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 88\n",
            "(1460, 1)\n",
            "RMSE: 0.07540381246548762\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 89\n",
            "(1460, 1)\n",
            "RMSE: 0.07541024176368422\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 90\n",
            "(1460, 1)\n",
            "RMSE: 0.07541604658886301\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 91\n",
            "(1460, 1)\n",
            "RMSE: 0.07526362116517352\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 92\n",
            "(1460, 1)\n",
            "RMSE: 0.0751429072127326\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 93\n",
            "(1460, 1)\n",
            "RMSE: 0.07514139965480564\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 94\n",
            "(1460, 1)\n",
            "RMSE: 0.07514455639724321\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 95\n",
            "(1460, 1)\n",
            "RMSE: 0.07514742428857633\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 96\n",
            "(1460, 1)\n",
            "RMSE: 0.07515002852374619\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 97\n",
            "(1460, 1)\n",
            "RMSE: 0.07515236664637687\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 98\n",
            "(1460, 1)\n",
            "RMSE: 0.07515444846299577\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 99\n",
            "(1460, 1)\n",
            "RMSE: 0.0751562720328342\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 100\n",
            "(1460, 1)\n",
            "RMSE: 0.07515783610600844\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 101\n",
            "(1460, 1)\n",
            "RMSE: 0.07506294145181445\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 102\n",
            "(1460, 1)\n",
            "RMSE: 0.07503901327703758\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 103\n",
            "(1460, 1)\n",
            "RMSE: 0.07503326367986057\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 104\n",
            "(1460, 1)\n",
            "RMSE: 0.07503239010574163\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 105\n",
            "(1460, 1)\n",
            "RMSE: 0.07503260267578502\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 106\n",
            "(1460, 1)\n",
            "RMSE: 0.07503303732231445\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 107\n",
            "(1460, 1)\n",
            "RMSE: 0.0750334572686923\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 108\n",
            "(1460, 1)\n",
            "RMSE: 0.07503379873226519\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 109\n",
            "(1460, 1)\n",
            "RMSE: 0.07503404233270326\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 110\n",
            "(1460, 1)\n",
            "RMSE: 0.07503421316777398\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 111\n",
            "(1460, 1)\n",
            "RMSE: 0.07497776620338702\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 112\n",
            "(1460, 1)\n",
            "RMSE: 0.07497447716591603\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 113\n",
            "(1460, 1)\n",
            "RMSE: 0.07497269250475982\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 114\n",
            "(1460, 1)\n",
            "RMSE: 0.07497188200664683\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 115\n",
            "(1460, 1)\n",
            "RMSE: 0.07497146376872735\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 116\n",
            "(1460, 1)\n",
            "RMSE: 0.0749712172317597\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 117\n",
            "(1460, 1)\n",
            "RMSE: 0.0749710224221279\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 118\n",
            "(1460, 1)\n",
            "RMSE: 0.0749708317278664\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 119\n",
            "(1460, 1)\n",
            "RMSE: 0.07497063472149286\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 120\n",
            "(1460, 1)\n",
            "RMSE: 0.07497040126161313\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 121\n",
            "(1460, 1)\n",
            "RMSE: 0.07493854284041762\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 122\n",
            "(1460, 1)\n",
            "RMSE: 0.07493836594329756\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 123\n",
            "(1460, 1)\n",
            "RMSE: 0.07493810469237773\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 124\n",
            "(1460, 1)\n",
            "RMSE: 0.07493790531176296\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 125\n",
            "(1460, 1)\n",
            "RMSE: 0.07493772580845605\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 126\n",
            "(1460, 1)\n",
            "RMSE: 0.07493754419521083\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 127\n",
            "(1460, 1)\n",
            "RMSE: 0.07493734841577648\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 128\n",
            "(1460, 1)\n",
            "RMSE: 0.07493713848768688\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 129\n",
            "(1460, 1)\n",
            "RMSE: 0.07493692299773409\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 130\n",
            "(1460, 1)\n",
            "RMSE: 0.07493669041236947\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 131\n",
            "(1460, 1)\n",
            "RMSE: 0.07491941898476616\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 132\n",
            "(1460, 1)\n",
            "RMSE: 0.07491943929167567\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 133\n",
            "(1460, 1)\n",
            "RMSE: 0.07491939114582635\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 134\n",
            "(1460, 1)\n",
            "RMSE: 0.07491933243630819\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 135\n",
            "(1460, 1)\n",
            "RMSE: 0.07491925742605879\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 136\n",
            "(1460, 1)\n",
            "RMSE: 0.07491916901716798\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 137\n",
            "(1460, 1)\n",
            "RMSE: 0.07491906661090901\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 138\n",
            "(1460, 1)\n",
            "RMSE: 0.07491895160368389\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 139\n",
            "(1460, 1)\n",
            "RMSE: 0.07491881720172539\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 140\n",
            "(1460, 1)\n",
            "RMSE: 0.07491868229419976\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 141\n",
            "(1460, 1)\n",
            "RMSE: 0.0749095813005489\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 142\n",
            "(1460, 1)\n",
            "RMSE: 0.07490956349877918\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 143\n",
            "(1460, 1)\n",
            "RMSE: 0.07490952703709303\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 144\n",
            "(1460, 1)\n",
            "RMSE: 0.07490948370431726\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 145\n",
            "(1460, 1)\n",
            "RMSE: 0.07490943556837507\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 146\n",
            "(1460, 1)\n",
            "RMSE: 0.07490937624296913\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 147\n",
            "(1460, 1)\n",
            "RMSE: 0.07490932252088729\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 148\n",
            "(1460, 1)\n",
            "RMSE: 0.074909259181446\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 149\n",
            "(1460, 1)\n",
            "RMSE: 0.07490918503235526\n",
            "The Learning rate is: 9.765625e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hNnSxG4Xt9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/imputed_data_ for Hybrid_both Ensemble.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NFAwhLBV18L",
        "colab_type": "code",
        "outputId": "aa763e13-8725-4fd9-dcaa-04ac79f9ff0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "mdf = pd.read_excel('/content/ML Ensemble Training.xlsx')\n",
        "print(mdf.head())\n",
        "x_train = mdf[['GRU','Hybrid']].values\n",
        "y_train=mdf[['Original']].values\n",
        "type(x_train),x_train.shape,type(y_train),y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Original         GRU      Hybrid\n",
            "0  238.189475  241.865651  241.090878\n",
            "1  230.814541  241.772144  241.680785\n",
            "2  226.499687  221.341593  219.743735\n",
            "3  194.864339  222.576206  222.125256\n",
            "4  196.105779  197.601099  197.240561\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, (63, 2), numpy.ndarray, (63, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMkDTrSJWq4A",
        "colab_type": "code",
        "outputId": "e7cc06f1-5ba8-488d-cbfe-824781d9a36e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ytest = pd.read_excel('/content/y_test.xlsx').values\n",
        "xtest = pd.read_excel('/content/x_test.xlsx').values\n",
        "type(ytest),ytest.shape,type(xtest),xtest.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, (718, 1), numpy.ndarray, (718, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biuI4SoCWwQ2",
        "colab_type": "code",
        "outputId": "6dfcdb02-1ff4-4c96-d5d4-30024f3fe12e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "gbr = ensemble.GradientBoostingRegressor()\n",
        "clf = SVR(kernel='linear')\n",
        "clf.fit(x_train,y_train)\n",
        "gbr.fit(x_train,y_train)\n",
        "reg = LinearRegression().fit(x_train, y_train)\n",
        "predictions = clf.predict(xtest)\n",
        "predictions2 = gbr.predict(xtest)\n",
        "lr_pred=reg.predict(xtest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQgXaguPWzsZ",
        "colab_type": "code",
        "outputId": "4b902523-cd5f-4e90-b30b-ed3e4d47bc2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "mse(ytest,predictions),mae(ytest,predictions),mse(ytest,predictions2),mae(ytest,predictions2),mse(ytest,lr_pred),mae(ytest,lr_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(151.81165936289236,\n",
              " 9.514375182095112,\n",
              " 292.0869235103149,\n",
              " 12.830268622277272,\n",
              " 152.17591804886598,\n",
              " 9.70050261184138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB8JWUOoajZe",
        "colab_type": "text"
      },
      "source": [
        "Random Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg7LsKsLZvDZ",
        "colab_type": "code",
        "outputId": "57f704d4-f040-43db-af71-53cbb22fd412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "df = pd.read_excel('/content/Random Missing.xlsx')\n",
        "df.replace(-1.0,np.nan,inplace=True)\n",
        "print(df.head())\n",
        "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0     Series\n",
            "0           0  64.262716\n",
            "1           1  51.184589\n",
            "2           2        NaN\n",
            "3           3        NaN\n",
            "4           4  59.402088\n",
            "Series    750\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Ey82JQcHYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "series_missing=np.copy(df.values)\n",
        "for i in range(1,len(df.values)):\n",
        "    if random.random()<= 0.10:\n",
        "        series_missing[i]=np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB4_M7eYcKk7",
        "colab_type": "code",
        "outputId": "3cfeafd4-9726-4570-e78a-a75b75d3ecaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df_missing = pd.DataFrame(series_missing,columns=['Series'])\n",
        "print(df_missing.isnull().sum())\n",
        "print(df.shape,df_missing.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Series    822\n",
            "dtype: int64\n",
            "(1461, 1) (1461, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oun6jYfdcNVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_missing.fillna(-1.0).to_excel('Random Further missing.xlsx')\n",
        "df_missing.fillna(-1.0).to_csv('miss_data.txt', header=None, index=None, sep='\\t', mode='a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPfZDgW4cQPa",
        "colab_type": "code",
        "outputId": "60f245d9-958b-4754-cfe7-92589c29ce21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python Hybrid.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From Hybrid.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "I0223 00:27:56.841311 140488953489280 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:From Hybrid.py:115: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0223 00:27:56.849101 140488953489280 module_wrapper.py:139] From Hybrid.py:115: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From Hybrid.py:118: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0223 00:27:56.849441 140488953489280 module_wrapper.py:139] From Hybrid.py:118: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-02-23 00:27:56.854991: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-02-23 00:27:56.855240: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2f76bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-23 00:27:56.855279: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-23 00:27:56.857363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-23 00:27:56.859654: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-02-23 00:27:56.859697: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (3114d6793ca9): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From Hybrid.py:121: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0223 00:27:56.860327 140488953489280 module_wrapper.py:139] From Hybrid.py:121: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From Hybrid.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0223 00:27:56.860735 140488953489280 module_wrapper.py:139] From Hybrid.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From Hybrid.py:32: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0223 00:27:56.862364 140488953489280 deprecation.py:323] From Hybrid.py:32: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From Hybrid.py:33: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0223 00:27:56.865185 140488953489280 deprecation.py:323] From Hybrid.py:33: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From Hybrid.py:34: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0223 00:27:56.865648 140488953489280 deprecation.py:323] From Hybrid.py:34: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "W0223 00:27:56.885503 140488953489280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0223 00:27:56.893772 140488953489280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0223 00:27:56.915682 140488953489280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From Hybrid.py:42: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0223 00:27:56.941411 140488953489280 module_wrapper.py:139] From Hybrid.py:42: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From Hybrid.py:50: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0223 00:27:56.948261 140488953489280 deprecation.py:323] From Hybrid.py:50: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From Hybrid.py:71: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0223 00:27:58.074824 140488953489280 module_wrapper.py:139] From Hybrid.py:71: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From Hybrid.py:74: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "W0223 00:28:01.862986 140488953489280 module_wrapper.py:139] From Hybrid.py:74: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "W0223 00:28:01.864129 140488953489280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "Number of iterations: 0\n",
            "(1460, 1)\n",
            "Number of iterations: 1\n",
            "(1460, 1)\n",
            "Number of iterations: 2\n",
            "(1460, 1)\n",
            "Number of iterations: 3\n",
            "(1460, 1)\n",
            "Number of iterations: 4\n",
            "(1460, 1)\n",
            "Number of iterations: 5\n",
            "(1460, 1)\n",
            "RMSE: 0.17891658932570662\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 6\n",
            "(1460, 1)\n",
            "RMSE: 0.17946401755644087\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 7\n",
            "(1460, 1)\n",
            "RMSE: 0.17870531086214192\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 8\n",
            "(1460, 1)\n",
            "RMSE: 0.17899668992987713\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 9\n",
            "(1460, 1)\n",
            "RMSE: 0.1787930977685341\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 10\n",
            "(1460, 1)\n",
            "RMSE: 0.17875071019786518\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 11\n",
            "(1460, 1)\n",
            "RMSE: 0.1780899938442657\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 12\n",
            "(1460, 1)\n",
            "RMSE: 0.1773215729018113\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 13\n",
            "(1460, 1)\n",
            "RMSE: 0.17725814623653754\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 14\n",
            "(1460, 1)\n",
            "RMSE: 0.17724531108200003\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 15\n",
            "(1460, 1)\n",
            "RMSE: 0.17722639834001158\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 16\n",
            "(1460, 1)\n",
            "RMSE: 0.17720267260399533\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 17\n",
            "(1460, 1)\n",
            "RMSE: 0.17717561962125722\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 18\n",
            "(1460, 1)\n",
            "RMSE: 0.17714658004029551\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 19\n",
            "(1460, 1)\n",
            "RMSE: 0.17711668252157572\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 20\n",
            "(1460, 1)\n",
            "RMSE: 0.1770868845146037\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 21\n",
            "(1460, 1)\n",
            "RMSE: 0.17636345302225093\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 22\n",
            "(1460, 1)\n",
            "RMSE: 0.17634454118104415\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 23\n",
            "(1460, 1)\n",
            "RMSE: 0.1763496944792455\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 24\n",
            "(1460, 1)\n",
            "RMSE: 0.17635599845544708\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 25\n",
            "(1460, 1)\n",
            "RMSE: 0.1763611203451131\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 26\n",
            "(1460, 1)\n",
            "RMSE: 0.1763650659318913\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 27\n",
            "(1460, 1)\n",
            "RMSE: 0.17636789591145985\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 28\n",
            "(1460, 1)\n",
            "RMSE: 0.17636966389137587\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 29\n",
            "(1460, 1)\n",
            "RMSE: 0.17637042441901082\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 30\n",
            "(1460, 1)\n",
            "RMSE: 0.17637025026392725\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 31\n",
            "(1460, 1)\n",
            "RMSE: 0.17593505322279934\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 32\n",
            "(1460, 1)\n",
            "RMSE: 0.17592089187450063\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 33\n",
            "(1460, 1)\n",
            "RMSE: 0.17592564420519174\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 34\n",
            "(1460, 1)\n",
            "RMSE: 0.175929345719894\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 35\n",
            "(1460, 1)\n",
            "RMSE: 0.17593286913022077\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 36\n",
            "(1460, 1)\n",
            "RMSE: 0.17593616353364222\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 37\n",
            "(1460, 1)\n",
            "RMSE: 0.17593922144378119\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 38\n",
            "(1460, 1)\n",
            "RMSE: 0.1759420513104429\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 39\n",
            "(1460, 1)\n",
            "RMSE: 0.1759446403725579\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 40\n",
            "(1460, 1)\n",
            "RMSE: 0.17594699044936857\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 41\n",
            "(1460, 1)\n",
            "RMSE: 0.1757259636231647\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 42\n",
            "(1460, 1)\n",
            "RMSE: 0.1757244442752512\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 43\n",
            "(1460, 1)\n",
            "RMSE: 0.17572611704058225\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 44\n",
            "(1460, 1)\n",
            "RMSE: 0.1757278556885773\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 45\n",
            "(1460, 1)\n",
            "RMSE: 0.17572956907741952\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 46\n",
            "(1460, 1)\n",
            "RMSE: 0.17573124596697642\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 47\n",
            "(1460, 1)\n",
            "RMSE: 0.175732887278928\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 48\n",
            "(1460, 1)\n",
            "RMSE: 0.1757344823048414\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 49\n",
            "(1460, 1)\n",
            "RMSE: 0.17573603521299402\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 50\n",
            "(1460, 1)\n",
            "RMSE: 0.17573753479509352\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 51\n",
            "(1460, 1)\n",
            "RMSE: 0.17562398913277277\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 52\n",
            "(1460, 1)\n",
            "RMSE: 0.1756237510409712\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 53\n",
            "(1460, 1)\n",
            "RMSE: 0.17562436308449983\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 54\n",
            "(1460, 1)\n",
            "RMSE: 0.17562510870158785\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 55\n",
            "(1460, 1)\n",
            "RMSE: 0.17562588836062307\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 56\n",
            "(1460, 1)\n",
            "RMSE: 0.17562667720252498\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 57\n",
            "(1460, 1)\n",
            "RMSE: 0.1756274701785055\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 58\n",
            "(1460, 1)\n",
            "RMSE: 0.17562825479226019\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 59\n",
            "(1460, 1)\n",
            "RMSE: 0.17562903532831692\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 60\n",
            "(1460, 1)\n",
            "RMSE: 0.17562980926583857\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 61\n",
            "(1460, 1)\n",
            "RMSE: 0.1755696554709938\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 62\n",
            "(1460, 1)\n",
            "RMSE: 0.17556958980645807\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 63\n",
            "(1460, 1)\n",
            "RMSE: 0.17556975576850858\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 64\n",
            "(1460, 1)\n",
            "RMSE: 0.1755700029464468\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 65\n",
            "(1460, 1)\n",
            "RMSE: 0.17557028676148004\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 66\n",
            "(1460, 1)\n",
            "RMSE: 0.175570589760281\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 67\n",
            "(1460, 1)\n",
            "RMSE: 0.17557090087875915\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 68\n",
            "(1460, 1)\n",
            "RMSE: 0.1755712140030644\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 69\n",
            "(1460, 1)\n",
            "RMSE: 0.17557152771403342\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 70\n",
            "(1460, 1)\n",
            "RMSE: 0.17557183968163229\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 71\n",
            "(1460, 1)\n",
            "RMSE: 0.17553928714904285\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 72\n",
            "(1460, 1)\n",
            "RMSE: 0.1755392527647337\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 73\n",
            "(1460, 1)\n",
            "RMSE: 0.1755392618576119\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 74\n",
            "(1460, 1)\n",
            "RMSE: 0.17553929349184644\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 75\n",
            "(1460, 1)\n",
            "RMSE: 0.17553933753497006\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 76\n",
            "(1460, 1)\n",
            "RMSE: 0.17553939174931651\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 77\n",
            "(1460, 1)\n",
            "RMSE: 0.17553945009664784\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 78\n",
            "(1460, 1)\n",
            "RMSE: 0.17553950838645105\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 79\n",
            "(1460, 1)\n",
            "RMSE: 0.17553956915318542\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 80\n",
            "(1460, 1)\n",
            "RMSE: 0.17553962908344906\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 81\n",
            "(1460, 1)\n",
            "RMSE: 0.1755219264400566\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 82\n",
            "(1460, 1)\n",
            "RMSE: 0.17552187534706623\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 83\n",
            "(1460, 1)\n",
            "RMSE: 0.1755218328803054\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 84\n",
            "(1460, 1)\n",
            "RMSE: 0.17552179107336718\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 85\n",
            "(1460, 1)\n",
            "RMSE: 0.17552175185108787\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 86\n",
            "(1460, 1)\n",
            "RMSE: 0.1755217143226522\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 87\n",
            "(1460, 1)\n",
            "RMSE: 0.17552167346343858\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 88\n",
            "(1460, 1)\n",
            "RMSE: 0.17552163430946813\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 89\n",
            "(1460, 1)\n",
            "RMSE: 0.17552159086002578\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 90\n",
            "(1460, 1)\n",
            "RMSE: 0.17552154605239612\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 91\n",
            "(1460, 1)\n",
            "RMSE: 0.17551199493382466\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 92\n",
            "(1460, 1)\n",
            "RMSE: 0.17551194410297635\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 93\n",
            "(1460, 1)\n",
            "RMSE: 0.17551189118765498\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 94\n",
            "(1460, 1)\n",
            "RMSE: 0.17551183626619304\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 95\n",
            "(1460, 1)\n",
            "RMSE: 0.17551178312934632\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 96\n",
            "(1460, 1)\n",
            "RMSE: 0.17551172650560226\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 97\n",
            "(1460, 1)\n",
            "RMSE: 0.1755116685478278\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 98\n",
            "(1460, 1)\n",
            "RMSE: 0.17551160936198967\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 99\n",
            "(1460, 1)\n",
            "RMSE: 0.17551154991652707\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 100\n",
            "(1460, 1)\n",
            "RMSE: 0.1755114877038794\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 101\n",
            "(1460, 1)\n",
            "RMSE: 0.17550640311220053\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 102\n",
            "(1460, 1)\n",
            "RMSE: 0.17550636095614072\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 103\n",
            "(1460, 1)\n",
            "RMSE: 0.17550631770878977\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 104\n",
            "(1460, 1)\n",
            "RMSE: 0.17550627371853858\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 105\n",
            "(1460, 1)\n",
            "RMSE: 0.17550622885183711\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 106\n",
            "(1460, 1)\n",
            "RMSE: 0.17550618302326582\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 107\n",
            "(1460, 1)\n",
            "RMSE: 0.17550613655000447\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 108\n",
            "(1460, 1)\n",
            "RMSE: 0.1755060882848148\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 109\n",
            "(1460, 1)\n",
            "RMSE: 0.1755060393849618\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 110\n",
            "(1460, 1)\n",
            "RMSE: 0.17550598881460977\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 111\n",
            "(1460, 1)\n",
            "RMSE: 0.17550331856584786\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 112\n",
            "(1460, 1)\n",
            "RMSE: 0.17550328954656966\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 113\n",
            "(1460, 1)\n",
            "RMSE: 0.17550326027341276\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 114\n",
            "(1460, 1)\n",
            "RMSE: 0.17550323084118133\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 115\n",
            "(1460, 1)\n",
            "RMSE: 0.17550320016568302\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 116\n",
            "(1460, 1)\n",
            "RMSE: 0.17550316822406786\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 117\n",
            "(1460, 1)\n",
            "RMSE: 0.17550313781154972\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 118\n",
            "(1460, 1)\n",
            "RMSE: 0.17550310530260946\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 119\n",
            "(1460, 1)\n",
            "RMSE: 0.17550307410434696\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 120\n",
            "(1460, 1)\n",
            "RMSE: 0.17550304043707377\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 121\n",
            "(1460, 1)\n",
            "RMSE: 0.17550165744239096\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 122\n",
            "(1460, 1)\n",
            "RMSE: 0.17550163922478157\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 123\n",
            "(1460, 1)\n",
            "RMSE: 0.17550162153070017\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 124\n",
            "(1460, 1)\n",
            "RMSE: 0.1755016027555073\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 125\n",
            "(1460, 1)\n",
            "RMSE: 0.17550158400611846\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 126\n",
            "(1460, 1)\n",
            "RMSE: 0.1755015654974768\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 127\n",
            "(1460, 1)\n",
            "RMSE: 0.17550154533207388\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 128\n",
            "(1460, 1)\n",
            "RMSE: 0.17550152691179097\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 129\n",
            "(1460, 1)\n",
            "RMSE: 0.17550150646922305\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 130\n",
            "(1460, 1)\n",
            "RMSE: 0.17550148658811096\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 131\n",
            "(1460, 1)\n",
            "RMSE: 0.17550077607404202\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 132\n",
            "(1460, 1)\n",
            "RMSE: 0.1755007661766159\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 133\n",
            "(1460, 1)\n",
            "RMSE: 0.1755007555542786\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 134\n",
            "(1460, 1)\n",
            "RMSE: 0.17550074470229715\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 135\n",
            "(1460, 1)\n",
            "RMSE: 0.17550073459175838\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 136\n",
            "(1460, 1)\n",
            "RMSE: 0.17550072422128793\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 137\n",
            "(1460, 1)\n",
            "RMSE: 0.17550071270881498\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 138\n",
            "(1460, 1)\n",
            "RMSE: 0.1755007018952025\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 139\n",
            "(1460, 1)\n",
            "RMSE: 0.175500691337634\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 140\n",
            "(1460, 1)\n",
            "RMSE: 0.17550067973311154\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 141\n",
            "(1460, 1)\n",
            "RMSE: 0.17550031766266277\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 142\n",
            "(1460, 1)\n",
            "RMSE: 0.1755003120127765\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 143\n",
            "(1460, 1)\n",
            "RMSE: 0.17550030643743958\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 144\n",
            "(1460, 1)\n",
            "RMSE: 0.17550030029912214\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 145\n",
            "(1460, 1)\n",
            "RMSE: 0.1755002950312333\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 146\n",
            "(1460, 1)\n",
            "RMSE: 0.17550028802845208\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 147\n",
            "(1460, 1)\n",
            "RMSE: 0.175500282702356\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 148\n",
            "(1460, 1)\n",
            "RMSE: 0.17550027593249318\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 149\n",
            "(1460, 1)\n",
            "RMSE: 0.17550027062447976\n",
            "The Learning rate is: 9.765625e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7YSG7wDcX3W",
        "colab_type": "code",
        "outputId": "7ec24a25-595c-4877-8f6b-fa34135c5e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python Residual.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From Residual.py:145: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "I0223 00:36:38.245556 140364871370624 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:From Residual.py:117: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0223 00:36:38.253382 140364871370624 module_wrapper.py:139] From Residual.py:117: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From Residual.py:120: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0223 00:36:38.253720 140364871370624 module_wrapper.py:139] From Residual.py:120: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-02-23 00:36:38.259517: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-02-23 00:36:38.259786: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29acbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-23 00:36:38.259825: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-23 00:36:38.262120: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-23 00:36:38.264291: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-02-23 00:36:38.264328: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (3114d6793ca9): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From Residual.py:123: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0223 00:36:38.264999 140364871370624 module_wrapper.py:139] From Residual.py:123: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From Residual.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0223 00:36:38.265449 140364871370624 module_wrapper.py:139] From Residual.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From Residual.py:33: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0223 00:36:38.267081 140364871370624 deprecation.py:323] From Residual.py:33: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From Residual.py:35: The name tf.nn.rnn_cell.ResidualWrapper is deprecated. Please use tf.compat.v1.nn.rnn_cell.ResidualWrapper instead.\n",
            "\n",
            "W0223 00:36:38.269436 140364871370624 module_wrapper.py:139] From Residual.py:35: The name tf.nn.rnn_cell.ResidualWrapper is deprecated. Please use tf.compat.v1.nn.rnn_cell.ResidualWrapper instead.\n",
            "\n",
            "WARNING:tensorflow:From Residual.py:36: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0223 00:36:38.270343 140364871370624 deprecation.py:323] From Residual.py:36: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "W0223 00:36:38.286053 140364871370624 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0223 00:36:38.294476 140364871370624 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0223 00:36:38.305691 140364871370624 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From Residual.py:44: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0223 00:36:38.355458 140364871370624 module_wrapper.py:139] From Residual.py:44: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From Residual.py:52: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0223 00:36:38.362475 140364871370624 deprecation.py:323] From Residual.py:52: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From Residual.py:73: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0223 00:36:39.556735 140364871370624 module_wrapper.py:139] From Residual.py:73: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From Residual.py:76: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "W0223 00:36:43.981815 140364871370624 module_wrapper.py:139] From Residual.py:76: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "W0223 00:36:43.983041 140364871370624 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "Number of iterations: 0\n",
            "(1460, 1)\n",
            "Number of iterations: 1\n",
            "(1460, 1)\n",
            "Number of iterations: 2\n",
            "(1460, 1)\n",
            "Number of iterations: 3\n",
            "(1460, 1)\n",
            "Number of iterations: 4\n",
            "(1460, 1)\n",
            "Number of iterations: 5\n",
            "(1460, 1)\n",
            "RMSE: 0.181251189358677\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 6\n",
            "(1460, 1)\n",
            "RMSE: 0.1801756047089841\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 7\n",
            "(1460, 1)\n",
            "RMSE: 0.18119735839318965\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 8\n",
            "(1460, 1)\n",
            "RMSE: 0.18068028720157508\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 9\n",
            "(1460, 1)\n",
            "RMSE: 0.18082805959745013\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 10\n",
            "(1460, 1)\n",
            "RMSE: 0.18068561436291153\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 11\n",
            "(1460, 1)\n",
            "RMSE: 0.17930145136131073\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 12\n",
            "(1460, 1)\n",
            "RMSE: 0.17861604974931375\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 13\n",
            "(1460, 1)\n",
            "RMSE: 0.17861776576057461\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 14\n",
            "(1460, 1)\n",
            "RMSE: 0.17865313698153165\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 15\n",
            "(1460, 1)\n",
            "RMSE: 0.17867701630416757\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 16\n",
            "(1460, 1)\n",
            "RMSE: 0.17869151344547637\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 17\n",
            "(1460, 1)\n",
            "RMSE: 0.17869887340284893\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 18\n",
            "(1460, 1)\n",
            "RMSE: 0.17870272419274238\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 19\n",
            "(1460, 1)\n",
            "RMSE: 0.1787115281390536\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 20\n",
            "(1460, 1)\n",
            "RMSE: 0.17874269485244937\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 21\n",
            "(1460, 1)\n",
            "RMSE: 0.17705654351885533\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 22\n",
            "(1460, 1)\n",
            "RMSE: 0.17698470811523212\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 23\n",
            "(1460, 1)\n",
            "RMSE: 0.17701136231373724\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 24\n",
            "(1460, 1)\n",
            "RMSE: 0.1770371200515802\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 25\n",
            "(1460, 1)\n",
            "RMSE: 0.17706109372949205\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 26\n",
            "(1460, 1)\n",
            "RMSE: 0.1770833220164771\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 27\n",
            "(1460, 1)\n",
            "RMSE: 0.1771037942298699\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 28\n",
            "(1460, 1)\n",
            "RMSE: 0.17712249229705065\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 29\n",
            "(1460, 1)\n",
            "RMSE: 0.17713942425319879\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 30\n",
            "(1460, 1)\n",
            "RMSE: 0.1771546014145438\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 31\n",
            "(1460, 1)\n",
            "RMSE: 0.17631352592224114\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 32\n",
            "(1460, 1)\n",
            "RMSE: 0.17628877839099863\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 33\n",
            "(1460, 1)\n",
            "RMSE: 0.1762966817740603\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 34\n",
            "(1460, 1)\n",
            "RMSE: 0.17630674584971734\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 35\n",
            "(1460, 1)\n",
            "RMSE: 0.176316300981572\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 36\n",
            "(1460, 1)\n",
            "RMSE: 0.1763253519686287\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 37\n",
            "(1460, 1)\n",
            "RMSE: 0.17633387880744472\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 38\n",
            "(1460, 1)\n",
            "RMSE: 0.1763418701834473\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 39\n",
            "(1460, 1)\n",
            "RMSE: 0.1763493107859365\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 40\n",
            "(1460, 1)\n",
            "RMSE: 0.17635619242769687\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 41\n",
            "(1460, 1)\n",
            "RMSE: 0.175931411755477\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 42\n",
            "(1460, 1)\n",
            "RMSE: 0.17591844635700393\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 43\n",
            "(1460, 1)\n",
            "RMSE: 0.17592282235574072\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 44\n",
            "(1460, 1)\n",
            "RMSE: 0.17592623714598735\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 45\n",
            "(1460, 1)\n",
            "RMSE: 0.17592955906131774\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 46\n",
            "(1460, 1)\n",
            "RMSE: 0.17593274549614038\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 47\n",
            "(1460, 1)\n",
            "RMSE: 0.1759357900495805\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 48\n",
            "(1460, 1)\n",
            "RMSE: 0.17593869139161242\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 49\n",
            "(1460, 1)\n",
            "RMSE: 0.17594143984665989\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 50\n",
            "(1460, 1)\n",
            "RMSE: 0.1759440468788382\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 51\n",
            "(1460, 1)\n",
            "RMSE: 0.17571841373936564\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 52\n",
            "(1460, 1)\n",
            "RMSE: 0.17571595944826432\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 53\n",
            "(1460, 1)\n",
            "RMSE: 0.17571695484747404\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 54\n",
            "(1460, 1)\n",
            "RMSE: 0.17571802524117444\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 55\n",
            "(1460, 1)\n",
            "RMSE: 0.17571907784285337\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 56\n",
            "(1460, 1)\n",
            "RMSE: 0.1757201144237968\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 57\n",
            "(1460, 1)\n",
            "RMSE: 0.17572112635765\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 58\n",
            "(1460, 1)\n",
            "RMSE: 0.1757221218792189\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 59\n",
            "(1460, 1)\n",
            "RMSE: 0.17572309267599195\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 60\n",
            "(1460, 1)\n",
            "RMSE: 0.17572404113378448\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 61\n",
            "(1460, 1)\n",
            "RMSE: 0.17560646216439643\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 62\n",
            "(1460, 1)\n",
            "RMSE: 0.17560566983057413\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 63\n",
            "(1460, 1)\n",
            "RMSE: 0.17560578698870852\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 64\n",
            "(1460, 1)\n",
            "RMSE: 0.17560603551396203\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 65\n",
            "(1460, 1)\n",
            "RMSE: 0.1756063201071316\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 66\n",
            "(1460, 1)\n",
            "RMSE: 0.17560661762926386\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 67\n",
            "(1460, 1)\n",
            "RMSE: 0.17560692121984006\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 68\n",
            "(1460, 1)\n",
            "RMSE: 0.17560722720510633\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 69\n",
            "(1460, 1)\n",
            "RMSE: 0.17560752876923857\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 70\n",
            "(1460, 1)\n",
            "RMSE: 0.17560783468919372\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 71\n",
            "(1460, 1)\n",
            "RMSE: 0.17554583340663335\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 72\n",
            "(1460, 1)\n",
            "RMSE: 0.1755454983441092\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 73\n",
            "(1460, 1)\n",
            "RMSE: 0.1755453967249752\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 74\n",
            "(1460, 1)\n",
            "RMSE: 0.17554536218667807\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 75\n",
            "(1460, 1)\n",
            "RMSE: 0.17554536149944636\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 76\n",
            "(1460, 1)\n",
            "RMSE: 0.17554538074800302\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 77\n",
            "(1460, 1)\n",
            "RMSE: 0.17554540781357147\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 78\n",
            "(1460, 1)\n",
            "RMSE: 0.17554544215042123\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 79\n",
            "(1460, 1)\n",
            "RMSE: 0.17554547628009295\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 80\n",
            "(1460, 1)\n",
            "RMSE: 0.1755455144185566\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 81\n",
            "(1460, 1)\n",
            "RMSE: 0.17551241401959325\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 82\n",
            "(1460, 1)\n",
            "RMSE: 0.17551225453944894\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 83\n",
            "(1460, 1)\n",
            "RMSE: 0.17551213902286478\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 84\n",
            "(1460, 1)\n",
            "RMSE: 0.17551204692988875\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 85\n",
            "(1460, 1)\n",
            "RMSE: 0.17551196270460398\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 86\n",
            "(1460, 1)\n",
            "RMSE: 0.17551188580009933\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 87\n",
            "(1460, 1)\n",
            "RMSE: 0.17551181418009398\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 88\n",
            "(1460, 1)\n",
            "RMSE: 0.1755117446650277\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 89\n",
            "(1460, 1)\n",
            "RMSE: 0.17551168018025556\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 90\n",
            "(1460, 1)\n",
            "RMSE: 0.17551161474421703\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 91\n",
            "(1460, 1)\n",
            "RMSE: 0.1754938467312233\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 92\n",
            "(1460, 1)\n",
            "RMSE: 0.17549375033233544\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 93\n",
            "(1460, 1)\n",
            "RMSE: 0.17549365680322182\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 94\n",
            "(1460, 1)\n",
            "RMSE: 0.17549356667440014\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 95\n",
            "(1460, 1)\n",
            "RMSE: 0.17549347715227456\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 96\n",
            "(1460, 1)\n",
            "RMSE: 0.17549339179396153\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 97\n",
            "(1460, 1)\n",
            "RMSE: 0.17549330285322726\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 98\n",
            "(1460, 1)\n",
            "RMSE: 0.17549321530179143\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 99\n",
            "(1460, 1)\n",
            "RMSE: 0.17549312779844167\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 100\n",
            "(1460, 1)\n",
            "RMSE: 0.17549303872531738\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 101\n",
            "(1460, 1)\n",
            "RMSE: 0.17548350524640297\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 102\n",
            "(1460, 1)\n",
            "RMSE: 0.17548343690195214\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 103\n",
            "(1460, 1)\n",
            "RMSE: 0.17548336400252043\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 104\n",
            "(1460, 1)\n",
            "RMSE: 0.17548329250667405\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 105\n",
            "(1460, 1)\n",
            "RMSE: 0.1754832204317032\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 106\n",
            "(1460, 1)\n",
            "RMSE: 0.17548314910550078\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 107\n",
            "(1460, 1)\n",
            "RMSE: 0.17548307534446367\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 108\n",
            "(1460, 1)\n",
            "RMSE: 0.17548300422362703\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 109\n",
            "(1460, 1)\n",
            "RMSE: 0.17548292847264926\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 110\n",
            "(1460, 1)\n",
            "RMSE: 0.1754828476850896\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 111\n",
            "(1460, 1)\n",
            "RMSE: 0.1754777524265203\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 112\n",
            "(1460, 1)\n",
            "RMSE: 0.17547770273227045\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 113\n",
            "(1460, 1)\n",
            "RMSE: 0.1754776521791861\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 114\n",
            "(1460, 1)\n",
            "RMSE: 0.17547760103203314\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 115\n",
            "(1460, 1)\n",
            "RMSE: 0.17547754836409443\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 116\n",
            "(1460, 1)\n",
            "RMSE: 0.1754774953043624\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 117\n",
            "(1460, 1)\n",
            "RMSE: 0.17547744065715193\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 118\n",
            "(1460, 1)\n",
            "RMSE: 0.17547738506399774\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 119\n",
            "(1460, 1)\n",
            "RMSE: 0.1754773298218271\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 120\n",
            "(1460, 1)\n",
            "RMSE: 0.17547727394753526\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 121\n",
            "(1460, 1)\n",
            "RMSE: 0.1754745646005802\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 122\n",
            "(1460, 1)\n",
            "RMSE: 0.17547452989077714\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 123\n",
            "(1460, 1)\n",
            "RMSE: 0.1754744974402186\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 124\n",
            "(1460, 1)\n",
            "RMSE: 0.1754744643127253\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 125\n",
            "(1460, 1)\n",
            "RMSE: 0.1754744266468423\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 126\n",
            "(1460, 1)\n",
            "RMSE: 0.1754743925648585\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 127\n",
            "(1460, 1)\n",
            "RMSE: 0.17547435522944452\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 128\n",
            "(1460, 1)\n",
            "RMSE: 0.17547431677740094\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 129\n",
            "(1460, 1)\n",
            "RMSE: 0.1754742780179283\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 130\n",
            "(1460, 1)\n",
            "RMSE: 0.17547424022502509\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 131\n",
            "(1460, 1)\n",
            "RMSE: 0.17547280600361978\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 132\n",
            "(1460, 1)\n",
            "RMSE: 0.17547278600360128\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 133\n",
            "(1460, 1)\n",
            "RMSE: 0.17547276485564398\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 134\n",
            "(1460, 1)\n",
            "RMSE: 0.1754727417431667\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 135\n",
            "(1460, 1)\n",
            "RMSE: 0.17547271698218894\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 136\n",
            "(1460, 1)\n",
            "RMSE: 0.17547269569536708\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 137\n",
            "(1460, 1)\n",
            "RMSE: 0.17547267210735842\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 138\n",
            "(1460, 1)\n",
            "RMSE: 0.17547264801160184\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 139\n",
            "(1460, 1)\n",
            "RMSE: 0.17547262266068034\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 140\n",
            "(1460, 1)\n",
            "RMSE: 0.1754725965803716\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 141\n",
            "(1460, 1)\n",
            "RMSE: 0.17547185158141476\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 142\n",
            "(1460, 1)\n",
            "RMSE: 0.17547183869358213\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 143\n",
            "(1460, 1)\n",
            "RMSE: 0.1754718243793013\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 144\n",
            "(1460, 1)\n",
            "RMSE: 0.17547181133759182\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 145\n",
            "(1460, 1)\n",
            "RMSE: 0.1754717969026618\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 146\n",
            "(1460, 1)\n",
            "RMSE: 0.17547178235588726\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 147\n",
            "(1460, 1)\n",
            "RMSE: 0.17547176784238264\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 148\n",
            "(1460, 1)\n",
            "RMSE: 0.17547175331193568\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 149\n",
            "(1460, 1)\n",
            "RMSE: 0.17547173829850332\n",
            "The Learning rate is: 9.765625e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OevxvJj7dH1o",
        "colab_type": "code",
        "outputId": "b494a0e5-0931-4c4c-9b76-b57406718b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "mdf = pd.read_excel('/content/ML Ensemble Training.xlsx')\n",
        "print(mdf.head())\n",
        "x_train = mdf[['Residual','Hybrid']].values\n",
        "y_train=mdf[['Original']].values\n",
        "type(x_train),x_train.shape,type(y_train),y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Original     Hybrid   Residual\n",
            "0  54.22838  49.069311  49.062313\n",
            "1  43.83395  49.069225  49.058518\n",
            "2  59.13587  49.063229  48.889733\n",
            "3  50.66887  49.103583  48.933853\n",
            "4  44.47127  49.078277  49.198943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, (72, 2), numpy.ndarray, (72, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSutsmIQdLUi",
        "colab_type": "code",
        "outputId": "103da5bc-5651-4b4b-aec6-7c4516d1d531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ytest = pd.read_excel('/content/y_test.xlsx').values\n",
        "xtest = pd.read_excel('/content/x_test.xlsx').values\n",
        "type(ytest),ytest.shape,type(xtest),xtest.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, (750, 1), numpy.ndarray, (750, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkmMiLlbdNe7",
        "colab_type": "code",
        "outputId": "eff29d8f-cd79-4b5d-9c69-8226599388ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "gbr = ensemble.GradientBoostingRegressor()\n",
        "clf = SVR(kernel='linear')\n",
        "clf.fit(x_train,y_train)\n",
        "gbr.fit(x_train,y_train)\n",
        "reg = LinearRegression().fit(x_train, y_train)\n",
        "predictions = clf.predict(xtest)\n",
        "predictions2 = gbr.predict(xtest)\n",
        "lr_pred=reg.predict(xtest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOUywW_LdP7O",
        "colab_type": "code",
        "outputId": "90bba356-dc5f-4e41-e4b0-0194ca04e484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "mse(ytest,predictions),mae(ytest,predictions),mse(ytest,predictions2),mae(ytest,predictions2),mse(ytest,lr_pred),mae(ytest,lr_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98.64632057835199,\n",
              " 7.931519706878161,\n",
              " 153.9117113357779,\n",
              " 9.91643871508676,\n",
              " 118.62206187363128,\n",
              " 8.576189780740886)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL1oZd4DFAVE",
        "colab_type": "text"
      },
      "source": [
        "# Price to Price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5zCeW2Ng8bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_excel('/content/LSP Need Interpolation.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twIyNLnIFSwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "11847b48-9f2f-4c47-9ab4-a32a630087c5"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Average Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-11-14</td>\n",
              "      <td>1.752856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-11-15</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-11-16</td>\n",
              "      <td>2.177029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-11-17</td>\n",
              "      <td>2.177029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-11-18</td>\n",
              "      <td>2.177029</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Average Price\n",
              "0 2012-11-14       1.752856\n",
              "1 2012-11-15            NaN\n",
              "2 2012-11-16       2.177029\n",
              "3 2012-11-17       2.177029\n",
              "4 2012-11-18       2.177029"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Uhr2P0FTj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_main=df[['Average Price']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEJ1-euZFYTE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c5cc085a-99f1-456b-f94a-04f00fe030ea"
      },
      "source": [
        "df_main.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Average Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.752856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.177029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.177029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.177029</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Average Price\n",
              "0       1.752856\n",
              "1            NaN\n",
              "2       2.177029\n",
              "3       2.177029\n",
              "4       2.177029"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS0hSiHkFZLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_main.fillna(-1.0).to_csv('miss_data.txt',header=None, index=None, sep='\\t', mode='a')\n",
        "df_main.fillna(-1.0).to_excel('LSP miss data.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlFvo7kMF0i7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "f7d19336-509d-4385-a9c1-393b44ee2de0"
      },
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(df['Date'],df['Average Price'])\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2AAAAI/CAYAAAARPboyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0TscGxBGt1G",
        "colab_type": "text"
      },
      "source": [
        "the above plot shows that it is seasonal data. So, Residual and LSTM-GRU-GRU are the best which will be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nztba1_GSm3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a55a3367-9895-4228-9dec-1e0ca64931cf"
      },
      "source": [
        "!python LSTM-GRU-GRU.py"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From LSTM-GRU-GRU.py:144: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "I0223 22:18:29.436404 140444446513024 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:From LSTM-GRU-GRU.py:116: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0223 22:18:29.443908 140444446513024 module_wrapper.py:139] From LSTM-GRU-GRU.py:116: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From LSTM-GRU-GRU.py:119: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0223 22:18:29.444257 140444446513024 module_wrapper.py:139] From LSTM-GRU-GRU.py:119: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-02-23 22:18:29.450321: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-02-23 22:18:29.450548: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b5cbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-23 22:18:29.450620: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-23 22:18:29.452667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-23 22:18:29.454512: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-02-23 22:18:29.454588: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f89ea73696ee): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From LSTM-GRU-GRU.py:122: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0223 22:18:29.455224 140444446513024 module_wrapper.py:139] From LSTM-GRU-GRU.py:122: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From LSTM-GRU-GRU.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0223 22:18:29.455709 140444446513024 module_wrapper.py:139] From LSTM-GRU-GRU.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From LSTM-GRU-GRU.py:32: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0223 22:18:29.457326 140444446513024 deprecation.py:323] From LSTM-GRU-GRU.py:32: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From LSTM-GRU-GRU.py:33: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0223 22:18:29.459913 140444446513024 deprecation.py:323] From LSTM-GRU-GRU.py:33: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From LSTM-GRU-GRU.py:35: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0223 22:18:29.460665 140444446513024 deprecation.py:323] From LSTM-GRU-GRU.py:35: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "W0223 22:18:29.486226 140444446513024 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0223 22:18:29.494716 140444446513024 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0223 22:18:29.519990 140444446513024 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From LSTM-GRU-GRU.py:43: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0223 22:18:29.584779 140444446513024 module_wrapper.py:139] From LSTM-GRU-GRU.py:43: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From LSTM-GRU-GRU.py:51: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0223 22:18:29.592148 140444446513024 deprecation.py:323] From LSTM-GRU-GRU.py:51: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From LSTM-GRU-GRU.py:72: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0223 22:18:31.219053 140444446513024 module_wrapper.py:139] From LSTM-GRU-GRU.py:72: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From LSTM-GRU-GRU.py:75: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "W0223 22:18:37.055843 140444446513024 module_wrapper.py:139] From LSTM-GRU-GRU.py:75: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "W0223 22:18:37.057070 140444446513024 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "Number of iterations: 0\n",
            "(2224, 1)\n",
            "Number of iterations: 1\n",
            "(2224, 1)\n",
            "Number of iterations: 2\n",
            "(2224, 1)\n",
            "Number of iterations: 3\n",
            "(2224, 1)\n",
            "Number of iterations: 4\n",
            "(2224, 1)\n",
            "Number of iterations: 5\n",
            "(2224, 1)\n",
            "RMSE: 0.07902921476252361\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 6\n",
            "(2224, 1)\n",
            "RMSE: 0.07975362255533949\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 7\n",
            "(2224, 1)\n",
            "RMSE: 0.08045499628644462\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 8\n",
            "(2224, 1)\n",
            "RMSE: 0.08065801492872157\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 9\n",
            "(2224, 1)\n",
            "RMSE: 0.07982255777040632\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 10\n",
            "(2224, 1)\n",
            "RMSE: 0.08030896959338489\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 11\n",
            "(2224, 1)\n",
            "RMSE: 0.07716432038979865\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 12\n",
            "(2224, 1)\n",
            "RMSE: 0.07852349003095883\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 13\n",
            "(2224, 1)\n",
            "RMSE: 0.07689873513477462\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 14\n",
            "(2224, 1)\n",
            "RMSE: 0.07721993753325351\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 15\n",
            "(2224, 1)\n",
            "RMSE: 0.07684994283292859\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 16\n",
            "(2224, 1)\n",
            "RMSE: 0.07636418565003618\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 17\n",
            "(2224, 1)\n",
            "RMSE: 0.07658939019990334\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 18\n",
            "(2224, 1)\n",
            "RMSE: 0.07623721632909758\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 19\n",
            "(2224, 1)\n",
            "RMSE: 0.0765366285476781\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 20\n",
            "(2224, 1)\n",
            "RMSE: 0.07621813768926948\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 21\n",
            "(2224, 1)\n",
            "RMSE: 0.07693560512166128\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 22\n",
            "(2224, 1)\n",
            "RMSE: 0.0786688026632303\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 23\n",
            "(2224, 1)\n",
            "RMSE: 0.07565435176692059\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 24\n",
            "(2224, 1)\n",
            "RMSE: 0.07520659664229955\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 25\n",
            "(2224, 1)\n",
            "RMSE: 0.07695792072049278\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 26\n",
            "(2224, 1)\n",
            "RMSE: 0.07636900892719406\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 27\n",
            "(2224, 1)\n",
            "RMSE: 0.07724065583431905\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 28\n",
            "(2224, 1)\n",
            "RMSE: 0.07625242591126537\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 29\n",
            "(2224, 1)\n",
            "RMSE: 0.07977113528629923\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 30\n",
            "(2224, 1)\n",
            "RMSE: 0.07794408949291938\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 31\n",
            "(2224, 1)\n",
            "RMSE: 0.0761989859030976\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 32\n",
            "(2224, 1)\n",
            "RMSE: 0.07455929457801697\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 33\n",
            "(2224, 1)\n",
            "RMSE: 0.0742058118807974\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 34\n",
            "(2224, 1)\n",
            "RMSE: 0.07403269763564357\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 35\n",
            "(2224, 1)\n",
            "RMSE: 0.07399402014652104\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 36\n",
            "(2224, 1)\n",
            "RMSE: 0.0739631578447932\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 37\n",
            "(2224, 1)\n",
            "RMSE: 0.07398397296955941\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 38\n",
            "(2224, 1)\n",
            "RMSE: 0.07401645637580251\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 39\n",
            "(2224, 1)\n",
            "RMSE: 0.07407790012781643\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 40\n",
            "(2224, 1)\n",
            "RMSE: 0.07415659817525817\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 41\n",
            "(2224, 1)\n",
            "RMSE: 0.07305599867403406\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 42\n",
            "(2224, 1)\n",
            "RMSE: 0.07282691113755141\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 43\n",
            "(2224, 1)\n",
            "RMSE: 0.0728076913572411\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 44\n",
            "(2224, 1)\n",
            "RMSE: 0.07278890538019799\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 45\n",
            "(2224, 1)\n",
            "RMSE: 0.07277426006689366\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 46\n",
            "(2224, 1)\n",
            "RMSE: 0.07276007885307703\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 47\n",
            "(2224, 1)\n",
            "RMSE: 0.07274647283560881\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 48\n",
            "(2224, 1)\n",
            "RMSE: 0.0727325163183597\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 49\n",
            "(2224, 1)\n",
            "RMSE: 0.07271841028531838\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 50\n",
            "(2224, 1)\n",
            "RMSE: 0.07270388516625391\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 51\n",
            "(2224, 1)\n",
            "RMSE: 0.072209802416792\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 52\n",
            "(2224, 1)\n",
            "RMSE: 0.07219726223349854\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 53\n",
            "(2224, 1)\n",
            "RMSE: 0.0721783757684222\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 54\n",
            "(2224, 1)\n",
            "RMSE: 0.0721587031900834\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 55\n",
            "(2224, 1)\n",
            "RMSE: 0.07213876690321573\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 56\n",
            "(2224, 1)\n",
            "RMSE: 0.0721176626725429\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 57\n",
            "(2224, 1)\n",
            "RMSE: 0.07209586374355591\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 58\n",
            "(2224, 1)\n",
            "RMSE: 0.07207335402173955\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 59\n",
            "(2224, 1)\n",
            "RMSE: 0.07205034059624381\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 60\n",
            "(2224, 1)\n",
            "RMSE: 0.07202687336166863\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 61\n",
            "(2224, 1)\n",
            "RMSE: 0.07178584090826949\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 62\n",
            "(2224, 1)\n",
            "RMSE: 0.07180272384047556\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 63\n",
            "(2224, 1)\n",
            "RMSE: 0.07179177366776605\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 64\n",
            "(2224, 1)\n",
            "RMSE: 0.07177823667548659\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 65\n",
            "(2224, 1)\n",
            "RMSE: 0.07176275944799829\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 66\n",
            "(2224, 1)\n",
            "RMSE: 0.07174555869070624\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 67\n",
            "(2224, 1)\n",
            "RMSE: 0.07172713120288757\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 68\n",
            "(2224, 1)\n",
            "RMSE: 0.07170779528216968\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 69\n",
            "(2224, 1)\n",
            "RMSE: 0.07168778954688586\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 70\n",
            "(2224, 1)\n",
            "RMSE: 0.07166726606042118\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 71\n",
            "(2224, 1)\n",
            "RMSE: 0.07154418912013658\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 72\n",
            "(2224, 1)\n",
            "RMSE: 0.0715436710738407\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 73\n",
            "(2224, 1)\n",
            "RMSE: 0.07153584936564217\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 74\n",
            "(2224, 1)\n",
            "RMSE: 0.07152842739661538\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 75\n",
            "(2224, 1)\n",
            "RMSE: 0.071520143938984\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 76\n",
            "(2224, 1)\n",
            "RMSE: 0.07151096494849005\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 77\n",
            "(2224, 1)\n",
            "RMSE: 0.07150100381265341\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 78\n",
            "(2224, 1)\n",
            "RMSE: 0.07149038731763431\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 79\n",
            "(2224, 1)\n",
            "RMSE: 0.07147922391936834\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 80\n",
            "(2224, 1)\n",
            "RMSE: 0.07146758931545966\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 81\n",
            "(2224, 1)\n",
            "RMSE: 0.07136742067918497\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 82\n",
            "(2224, 1)\n",
            "RMSE: 0.07134445471669938\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 83\n",
            "(2224, 1)\n",
            "RMSE: 0.07133899464334077\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 84\n",
            "(2224, 1)\n",
            "RMSE: 0.07133413228766636\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 85\n",
            "(2224, 1)\n",
            "RMSE: 0.07132916977666598\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 86\n",
            "(2224, 1)\n",
            "RMSE: 0.07132394425398353\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 87\n",
            "(2224, 1)\n",
            "RMSE: 0.07131842432229817\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 88\n",
            "(2224, 1)\n",
            "RMSE: 0.07131261506143585\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 89\n",
            "(2224, 1)\n",
            "RMSE: 0.07130654089455633\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 90\n",
            "(2224, 1)\n",
            "RMSE: 0.07130022268147744\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 91\n",
            "(2224, 1)\n",
            "RMSE: 0.07123176234875962\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 92\n",
            "(2224, 1)\n",
            "RMSE: 0.07121812426733823\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 93\n",
            "(2224, 1)\n",
            "RMSE: 0.0712131243713616\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 94\n",
            "(2224, 1)\n",
            "RMSE: 0.07120940852814688\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 95\n",
            "(2224, 1)\n",
            "RMSE: 0.07120590550635414\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 96\n",
            "(2224, 1)\n",
            "RMSE: 0.07120239862544957\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 97\n",
            "(2224, 1)\n",
            "RMSE: 0.07119883865473808\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 98\n",
            "(2224, 1)\n",
            "RMSE: 0.07119520231210337\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 99\n",
            "(2224, 1)\n",
            "RMSE: 0.07119148771793296\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 100\n",
            "(2224, 1)\n",
            "RMSE: 0.07118769387593542\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 101\n",
            "(2224, 1)\n",
            "RMSE: 0.07115209733500702\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 102\n",
            "(2224, 1)\n",
            "RMSE: 0.07114564803996071\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 103\n",
            "(2224, 1)\n",
            "RMSE: 0.0711416278916182\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 104\n",
            "(2224, 1)\n",
            "RMSE: 0.07113863599875837\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 105\n",
            "(2224, 1)\n",
            "RMSE: 0.07113610547918638\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 106\n",
            "(2224, 1)\n",
            "RMSE: 0.07113377781667475\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 107\n",
            "(2224, 1)\n",
            "RMSE: 0.07113153403109577\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 108\n",
            "(2224, 1)\n",
            "RMSE: 0.0711293215689828\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 109\n",
            "(2224, 1)\n",
            "RMSE: 0.07112711034527888\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 110\n",
            "(2224, 1)\n",
            "RMSE: 0.07112489063059393\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 111\n",
            "(2224, 1)\n",
            "RMSE: 0.07110725181246336\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 112\n",
            "(2224, 1)\n",
            "RMSE: 0.07110457431234649\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 113\n",
            "(2224, 1)\n",
            "RMSE: 0.07110238754135607\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 114\n",
            "(2224, 1)\n",
            "RMSE: 0.07110051457106709\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 115\n",
            "(2224, 1)\n",
            "RMSE: 0.07109885261249346\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 116\n",
            "(2224, 1)\n",
            "RMSE: 0.07109733710250371\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 117\n",
            "(2224, 1)\n",
            "RMSE: 0.0710959131348466\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 118\n",
            "(2224, 1)\n",
            "RMSE: 0.071094553640755\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 119\n",
            "(2224, 1)\n",
            "RMSE: 0.07109323603741079\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 120\n",
            "(2224, 1)\n",
            "RMSE: 0.07109194495988252\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 121\n",
            "(2224, 1)\n",
            "RMSE: 0.07108314529450455\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 122\n",
            "(2224, 1)\n",
            "RMSE: 0.07108205655829519\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 123\n",
            "(2224, 1)\n",
            "RMSE: 0.07108104542732768\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 124\n",
            "(2224, 1)\n",
            "RMSE: 0.07108009688482901\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 125\n",
            "(2224, 1)\n",
            "RMSE: 0.0710792010541917\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 126\n",
            "(2224, 1)\n",
            "RMSE: 0.07107834582386276\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 127\n",
            "(2224, 1)\n",
            "RMSE: 0.07107752739504213\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 128\n",
            "(2224, 1)\n",
            "RMSE: 0.07107673821106779\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 129\n",
            "(2224, 1)\n",
            "RMSE: 0.07107597048510979\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 130\n",
            "(2224, 1)\n",
            "RMSE: 0.0710752229213764\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 131\n",
            "(2224, 1)\n",
            "RMSE: 0.07107078890538009\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 132\n",
            "(2224, 1)\n",
            "RMSE: 0.07107030089802731\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 133\n",
            "(2224, 1)\n",
            "RMSE: 0.07106982987504397\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 134\n",
            "(2224, 1)\n",
            "RMSE: 0.07106936873224098\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 135\n",
            "(2224, 1)\n",
            "RMSE: 0.07106891705891545\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 136\n",
            "(2224, 1)\n",
            "RMSE: 0.07106847798423728\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 137\n",
            "(2224, 1)\n",
            "RMSE: 0.07106804683052084\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 138\n",
            "(2224, 1)\n",
            "RMSE: 0.071067624052898\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 139\n",
            "(2224, 1)\n",
            "RMSE: 0.07106720849134672\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 140\n",
            "(2224, 1)\n",
            "RMSE: 0.07106679952806191\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 141\n",
            "(2224, 1)\n",
            "RMSE: 0.07106456763321252\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 142\n",
            "(2224, 1)\n",
            "RMSE: 0.07106433409031469\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 143\n",
            "(2224, 1)\n",
            "RMSE: 0.0710641038028203\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 144\n",
            "(2224, 1)\n",
            "RMSE: 0.07106387859285503\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 145\n",
            "(2224, 1)\n",
            "RMSE: 0.07106365237106702\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 146\n",
            "(2224, 1)\n",
            "RMSE: 0.07106343025093001\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 147\n",
            "(2224, 1)\n",
            "RMSE: 0.07106321113483406\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 148\n",
            "(2224, 1)\n",
            "RMSE: 0.07106299251946435\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 149\n",
            "(2224, 1)\n",
            "RMSE: 0.07106277654684841\n",
            "The Learning rate is: 9.765625e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIjLBITnHLGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "faa34df6-2403-406e-935e-3a2866559e67"
      },
      "source": [
        "!python Residual.py"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From Residual.py:145: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "I0223 22:34:08.249019 140159888004992 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:From Residual.py:117: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0223 22:34:08.257464 140159888004992 module_wrapper.py:139] From Residual.py:117: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From Residual.py:120: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0223 22:34:08.257816 140159888004992 module_wrapper.py:139] From Residual.py:120: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-02-23 22:34:08.264042: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-02-23 22:34:08.264307: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22fcbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-23 22:34:08.264342: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-23 22:34:08.266481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-23 22:34:08.268330: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-02-23 22:34:08.268375: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f89ea73696ee): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From Residual.py:123: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0223 22:34:08.269051 140159888004992 module_wrapper.py:139] From Residual.py:123: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From Residual.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0223 22:34:08.269512 140159888004992 module_wrapper.py:139] From Residual.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From Residual.py:33: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0223 22:34:08.271304 140159888004992 deprecation.py:323] From Residual.py:33: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From Residual.py:35: The name tf.nn.rnn_cell.ResidualWrapper is deprecated. Please use tf.compat.v1.nn.rnn_cell.ResidualWrapper instead.\n",
            "\n",
            "W0223 22:34:08.273568 140159888004992 module_wrapper.py:139] From Residual.py:35: The name tf.nn.rnn_cell.ResidualWrapper is deprecated. Please use tf.compat.v1.nn.rnn_cell.ResidualWrapper instead.\n",
            "\n",
            "WARNING:tensorflow:From Residual.py:36: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0223 22:34:08.274309 140159888004992 deprecation.py:323] From Residual.py:36: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "W0223 22:34:08.290612 140159888004992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0223 22:34:08.299514 140159888004992 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0223 22:34:08.312864 140159888004992 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From Residual.py:44: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0223 22:34:08.364573 140159888004992 module_wrapper.py:139] From Residual.py:44: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From Residual.py:52: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0223 22:34:08.372848 140159888004992 deprecation.py:323] From Residual.py:52: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From Residual.py:73: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0223 22:34:09.665260 140159888004992 module_wrapper.py:139] From Residual.py:73: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From Residual.py:76: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "W0223 22:34:14.531747 140159888004992 module_wrapper.py:139] From Residual.py:76: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "W0223 22:34:14.532975 140159888004992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "Number of iterations: 0\n",
            "(2224, 1)\n",
            "Number of iterations: 1\n",
            "(2224, 1)\n",
            "Number of iterations: 2\n",
            "(2224, 1)\n",
            "Number of iterations: 3\n",
            "(2224, 1)\n",
            "Number of iterations: 4\n",
            "(2224, 1)\n",
            "Number of iterations: 5\n",
            "(2224, 1)\n",
            "RMSE: 0.07784639650035009\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 6\n",
            "(2224, 1)\n",
            "RMSE: 0.07762018498799449\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 7\n",
            "(2224, 1)\n",
            "RMSE: 0.07749244033623531\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 8\n",
            "(2224, 1)\n",
            "RMSE: 0.07742369593685307\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 9\n",
            "(2224, 1)\n",
            "RMSE: 0.0773871858354032\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 10\n",
            "(2224, 1)\n",
            "RMSE: 0.07736737473754818\n",
            "The Learning rate is: 0.01\n",
            "Number of iterations: 11\n",
            "(2224, 1)\n",
            "RMSE: 0.0756987351588804\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 12\n",
            "(2224, 1)\n",
            "RMSE: 0.07601805206302116\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 13\n",
            "(2224, 1)\n",
            "RMSE: 0.07605552468313971\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 14\n",
            "(2224, 1)\n",
            "RMSE: 0.07613124497958543\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 15\n",
            "(2224, 1)\n",
            "RMSE: 0.0762051567938259\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 16\n",
            "(2224, 1)\n",
            "RMSE: 0.07626540888111065\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 17\n",
            "(2224, 1)\n",
            "RMSE: 0.07632026731445707\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 18\n",
            "(2224, 1)\n",
            "RMSE: 0.07636772495243524\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 19\n",
            "(2224, 1)\n",
            "RMSE: 0.07640970686829976\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 20\n",
            "(2224, 1)\n",
            "RMSE: 0.07644682772779911\n",
            "The Learning rate is: 0.007\n",
            "Number of iterations: 21\n",
            "(2224, 1)\n",
            "RMSE: 0.07525801432316485\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 22\n",
            "(2224, 1)\n",
            "RMSE: 0.0753717722383262\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 23\n",
            "(2224, 1)\n",
            "RMSE: 0.0753762012940795\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 24\n",
            "(2224, 1)\n",
            "RMSE: 0.07540263017620147\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 25\n",
            "(2224, 1)\n",
            "RMSE: 0.07544162879557485\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 26\n",
            "(2224, 1)\n",
            "RMSE: 0.07548785610814343\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 27\n",
            "(2224, 1)\n",
            "RMSE: 0.07553543207456187\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 28\n",
            "(2224, 1)\n",
            "RMSE: 0.07557960453967828\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 29\n",
            "(2224, 1)\n",
            "RMSE: 0.07561797542899884\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 30\n",
            "(2224, 1)\n",
            "RMSE: 0.07565018762378371\n",
            "The Learning rate is: 0.004\n",
            "Number of iterations: 31\n",
            "(2224, 1)\n",
            "RMSE: 0.07510631934575411\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 32\n",
            "(2224, 1)\n",
            "RMSE: 0.07526062041245363\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 33\n",
            "(2224, 1)\n",
            "RMSE: 0.0752491206554382\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 34\n",
            "(2224, 1)\n",
            "RMSE: 0.07522665408483266\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 35\n",
            "(2224, 1)\n",
            "RMSE: 0.0752024119058252\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 36\n",
            "(2224, 1)\n",
            "RMSE: 0.07517560184862132\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 37\n",
            "(2224, 1)\n",
            "RMSE: 0.07514586030546222\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 38\n",
            "(2224, 1)\n",
            "RMSE: 0.07511335830634917\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 39\n",
            "(2224, 1)\n",
            "RMSE: 0.07507857208861218\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 40\n",
            "(2224, 1)\n",
            "RMSE: 0.0750422118614743\n",
            "The Learning rate is: 0.002\n",
            "Number of iterations: 41\n",
            "(2224, 1)\n",
            "RMSE: 0.07448224598424164\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 42\n",
            "(2224, 1)\n",
            "RMSE: 0.07445093657653992\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 43\n",
            "(2224, 1)\n",
            "RMSE: 0.07445177953614822\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 44\n",
            "(2224, 1)\n",
            "RMSE: 0.07445563748344984\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 45\n",
            "(2224, 1)\n",
            "RMSE: 0.07446034258423989\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 46\n",
            "(2224, 1)\n",
            "RMSE: 0.07446459521352837\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 47\n",
            "(2224, 1)\n",
            "RMSE: 0.07446737239360031\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 48\n",
            "(2224, 1)\n",
            "RMSE: 0.07446802593650513\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 49\n",
            "(2224, 1)\n",
            "RMSE: 0.0744663629483021\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 50\n",
            "(2224, 1)\n",
            "RMSE: 0.07446255425233222\n",
            "The Learning rate is: 0.001\n",
            "Number of iterations: 51\n",
            "(2224, 1)\n",
            "RMSE: 0.07407527189685506\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 52\n",
            "(2224, 1)\n",
            "RMSE: 0.0740646323072327\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 53\n",
            "(2224, 1)\n",
            "RMSE: 0.07405792358545561\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 54\n",
            "(2224, 1)\n",
            "RMSE: 0.07405282231914868\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 55\n",
            "(2224, 1)\n",
            "RMSE: 0.07404860325314297\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 56\n",
            "(2224, 1)\n",
            "RMSE: 0.07404467660784067\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 57\n",
            "(2224, 1)\n",
            "RMSE: 0.0740406873781023\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 58\n",
            "(2224, 1)\n",
            "RMSE: 0.07403643014019029\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 59\n",
            "(2224, 1)\n",
            "RMSE: 0.07403179791401521\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 60\n",
            "(2224, 1)\n",
            "RMSE: 0.0740267589825025\n",
            "The Learning rate is: 0.0005\n",
            "Number of iterations: 61\n",
            "(2224, 1)\n",
            "RMSE: 0.07387198235439058\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 62\n",
            "(2224, 1)\n",
            "RMSE: 0.07386395265810723\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 63\n",
            "(2224, 1)\n",
            "RMSE: 0.07386051339709658\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 64\n",
            "(2224, 1)\n",
            "RMSE: 0.07385749355242985\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 65\n",
            "(2224, 1)\n",
            "RMSE: 0.07385427232211166\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 66\n",
            "(2224, 1)\n",
            "RMSE: 0.0738507912041256\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 67\n",
            "(2224, 1)\n",
            "RMSE: 0.07384703973482679\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 68\n",
            "(2224, 1)\n",
            "RMSE: 0.07384301807413682\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 69\n",
            "(2224, 1)\n",
            "RMSE: 0.07383873840699383\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 70\n",
            "(2224, 1)\n",
            "RMSE: 0.07383418985426984\n",
            "The Learning rate is: 0.00025\n",
            "Number of iterations: 71\n",
            "(2224, 1)\n",
            "RMSE: 0.07374443699878075\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 72\n",
            "(2224, 1)\n",
            "RMSE: 0.07375699115896005\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 73\n",
            "(2224, 1)\n",
            "RMSE: 0.07375412711730427\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 74\n",
            "(2224, 1)\n",
            "RMSE: 0.0737510245822649\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 75\n",
            "(2224, 1)\n",
            "RMSE: 0.07374782152490883\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 76\n",
            "(2224, 1)\n",
            "RMSE: 0.07374451467290438\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 77\n",
            "(2224, 1)\n",
            "RMSE: 0.0737411092442965\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 78\n",
            "(2224, 1)\n",
            "RMSE: 0.07373760328588436\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 79\n",
            "(2224, 1)\n",
            "RMSE: 0.07373400491791297\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 80\n",
            "(2224, 1)\n",
            "RMSE: 0.07373031068490962\n",
            "The Learning rate is: 0.000125\n",
            "Number of iterations: 81\n",
            "(2224, 1)\n",
            "RMSE: 0.0736767995129776\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 82\n",
            "(2224, 1)\n",
            "RMSE: 0.07367675932330135\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 83\n",
            "(2224, 1)\n",
            "RMSE: 0.07367396792861003\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 84\n",
            "(2224, 1)\n",
            "RMSE: 0.07367178264382668\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 85\n",
            "(2224, 1)\n",
            "RMSE: 0.07366958359798043\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 86\n",
            "(2224, 1)\n",
            "RMSE: 0.07366734989745444\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 87\n",
            "(2224, 1)\n",
            "RMSE: 0.0736650851069163\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 88\n",
            "(2224, 1)\n",
            "RMSE: 0.07366278444271167\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 89\n",
            "(2224, 1)\n",
            "RMSE: 0.07366044625126823\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 90\n",
            "(2224, 1)\n",
            "RMSE: 0.07365807399154575\n",
            "The Learning rate is: 6.25e-05\n",
            "Number of iterations: 91\n",
            "(2224, 1)\n",
            "RMSE: 0.0736009982298892\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 92\n",
            "(2224, 1)\n",
            "RMSE: 0.07360007785721505\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 93\n",
            "(2224, 1)\n",
            "RMSE: 0.07359992908858991\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 94\n",
            "(2224, 1)\n",
            "RMSE: 0.0735989628298493\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 95\n",
            "(2224, 1)\n",
            "RMSE: 0.07359770235408711\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 96\n",
            "(2224, 1)\n",
            "RMSE: 0.07359630979133053\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 97\n",
            "(2224, 1)\n",
            "RMSE: 0.07359484916974816\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 98\n",
            "(2224, 1)\n",
            "RMSE: 0.07359334845392147\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 99\n",
            "(2224, 1)\n",
            "RMSE: 0.07359181399780183\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 100\n",
            "(2224, 1)\n",
            "RMSE: 0.07359025279124531\n",
            "The Learning rate is: 3.125e-05\n",
            "Number of iterations: 101\n",
            "(2224, 1)\n",
            "RMSE: 0.07355321127834291\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 102\n",
            "(2224, 1)\n",
            "RMSE: 0.07355285961684416\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 103\n",
            "(2224, 1)\n",
            "RMSE: 0.07355284158820177\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 104\n",
            "(2224, 1)\n",
            "RMSE: 0.07355248974604994\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 105\n",
            "(2224, 1)\n",
            "RMSE: 0.07355191178554162\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 106\n",
            "(2224, 1)\n",
            "RMSE: 0.07355118601445149\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 107\n",
            "(2224, 1)\n",
            "RMSE: 0.07355035533252964\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 108\n",
            "(2224, 1)\n",
            "RMSE: 0.07354945872763609\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 109\n",
            "(2224, 1)\n",
            "RMSE: 0.07354851233549571\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 110\n",
            "(2224, 1)\n",
            "RMSE: 0.07354752890231037\n",
            "The Learning rate is: 1.5625e-05\n",
            "Number of iterations: 111\n",
            "(2224, 1)\n",
            "RMSE: 0.07352743702862687\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 112\n",
            "(2224, 1)\n",
            "RMSE: 0.07352712915491998\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 113\n",
            "(2224, 1)\n",
            "RMSE: 0.07352693023287643\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 114\n",
            "(2224, 1)\n",
            "RMSE: 0.07352667111041342\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 115\n",
            "(2224, 1)\n",
            "RMSE: 0.07352634829051066\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 116\n",
            "(2224, 1)\n",
            "RMSE: 0.07352596635923765\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 117\n",
            "(2224, 1)\n",
            "RMSE: 0.07352553424190521\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 118\n",
            "(2224, 1)\n",
            "RMSE: 0.07352505918726003\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 119\n",
            "(2224, 1)\n",
            "RMSE: 0.0735245497056985\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 120\n",
            "(2224, 1)\n",
            "RMSE: 0.073524009802861\n",
            "The Learning rate is: 7.8125e-06\n",
            "Number of iterations: 121\n",
            "(2224, 1)\n",
            "RMSE: 0.07351351000049271\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 122\n",
            "(2224, 1)\n",
            "RMSE: 0.07351330104460432\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 123\n",
            "(2224, 1)\n",
            "RMSE: 0.07351311190654544\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 124\n",
            "(2224, 1)\n",
            "RMSE: 0.07351291414703436\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 125\n",
            "(2224, 1)\n",
            "RMSE: 0.07351270090281163\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 126\n",
            "(2224, 1)\n",
            "RMSE: 0.07351247154862067\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 127\n",
            "(2224, 1)\n",
            "RMSE: 0.07351222749772984\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 128\n",
            "(2224, 1)\n",
            "RMSE: 0.07351196952943712\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 129\n",
            "(2224, 1)\n",
            "RMSE: 0.07351169814272636\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 130\n",
            "(2224, 1)\n",
            "RMSE: 0.07351141404616632\n",
            "The Learning rate is: 3.90625e-06\n",
            "Number of iterations: 131\n",
            "(2224, 1)\n",
            "RMSE: 0.07350599392308943\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 132\n",
            "(2224, 1)\n",
            "RMSE: 0.07350586847222193\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 133\n",
            "(2224, 1)\n",
            "RMSE: 0.07350574573247129\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 134\n",
            "(2224, 1)\n",
            "RMSE: 0.07350561928558466\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 135\n",
            "(2224, 1)\n",
            "RMSE: 0.07350549048370636\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 136\n",
            "(2224, 1)\n",
            "RMSE: 0.07350535737597601\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 137\n",
            "(2224, 1)\n",
            "RMSE: 0.07350521580186532\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 138\n",
            "(2224, 1)\n",
            "RMSE: 0.07350507303816474\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 139\n",
            "(2224, 1)\n",
            "RMSE: 0.07350492646607618\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 140\n",
            "(2224, 1)\n",
            "RMSE: 0.07350477449412558\n",
            "The Learning rate is: 1.953125e-06\n",
            "Number of iterations: 141\n",
            "(2224, 1)\n",
            "RMSE: 0.07350199707431097\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 142\n",
            "(2224, 1)\n",
            "RMSE: 0.07350192537084167\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 143\n",
            "(2224, 1)\n",
            "RMSE: 0.07350185360510542\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 144\n",
            "(2224, 1)\n",
            "RMSE: 0.073501781951095\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 145\n",
            "(2224, 1)\n",
            "RMSE: 0.07350170807772761\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 146\n",
            "(2224, 1)\n",
            "RMSE: 0.07350163256712439\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 147\n",
            "(2224, 1)\n",
            "RMSE: 0.07350155586146832\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 148\n",
            "(2224, 1)\n",
            "RMSE: 0.07350147762424296\n",
            "The Learning rate is: 9.765625e-07\n",
            "Number of iterations: 149\n",
            "(2224, 1)\n",
            "RMSE: 0.07350139952484605\n",
            "The Learning rate is: 9.765625e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUxShDqmL6Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}